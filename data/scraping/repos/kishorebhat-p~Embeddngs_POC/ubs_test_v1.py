# -*- coding: utf-8 -*-
"""UBS_test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QLjxzYchD6cIzbNb2zid_oXXodTBTloY
"""

#!pip install openai num2words matplotlib plotly scipy scikit-learn pandas tiktoken

import openai
import os
import re
import requests
import sys
from num2words import num2words
import os
import pandas as pd
import numpy as np
from openai.embeddings_utils import get_embedding, cosine_similarity
import tiktoken


openai.api_type = "azure"
openai.api_base = "https://openai-pocfsstar.openai.azure.com/"
openai.api_version = "2022-12-01"
os.environ["OPENAI_API_KEY"] = "************************"
openai.api_key = os.getenv("OPENAI_API_KEY")




df=pd.read_excel('./AppInventory_Sample_0822.xlsx')


import re
def normalize_text(s, sep_token = " \n "):
    s = re.sub(r'\s+',  ' ', s).strip()
    s = re.sub(r". ,","",s)
    # remove all instances of multiple spaces
    s = s.replace("..",".")
    s = s.replace(". .",".")
    s = s.replace("\n", "")
    s = s.replace("-", "")
    s = s.strip()
    return s

df['Software Description']= df['Software Description'].apply(lambda x : normalize_text(x))

tokenizer = tiktoken.get_encoding("cl100k_base")
df['n_tokens'] = df['Software Description'].apply(lambda x: len(tokenizer.encode(x)))
#df = df[df.n_tokens<500]
print("lenght of array")
print(len(df))
print("done")

#df = df.head(3)

import time
results = []
for ind in df.index:
   text=df['Software Description'][ind]
   embed = get_embedding(text, engine = 'star-embedding-ada')
   filename= "./persistnpy/" + str(df['IDENTIFIER'][ind]) + ".txt"
   embed = get_embedding(text, engine = 'star-embedding-ada')
   np.save(filename,embed)
   results.append(embed)
   time.sleep(3)
   print("Done with " + str(ind))
