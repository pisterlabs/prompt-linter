import openai
import requests
from youtube_transcript_api import YouTubeTranscriptApi
from youtube_transcript_api.formatters import TextFormatter
from pytube import extract
from bait_biter import prompts, models_config

import tiktoken

import logging

import nltk
from nltk.stem import PorterStemmer
from nltk.tokenize import word_tokenize

nltk.download("punkt")


class ClickbaitVideo:
    """
    A class that represents a clickbaity YouTube video that can use GPT-3 to generate the question
    that arises from the video title and an answer to that question based on the video transcript.

    Attributes:
        yt_url (str):    The YouTube video URL
        api_key (str):   An OpenAI API key for the GPT-3 model
        video_id (str):  The YouTube video ID
        title (str):     The title of the YouTube video
        transcript(str): A transcript of the video based on human- or autogenerated subtitles
        question(str):   A GPT3-powered transformation of the video title into a question
        answer_model_type(str): The model type to be used for answering, either 'text-curie-001' or 'text-davinci-003'
    """

    def __init__(
        self,
        yt_url: str,
        api_key: str,
        gpt_model: str = models_config.SMALL_MODEL,
    ):
        self.logger = logging.Logger('logger')
        self.tokenizer = tiktoken.encoding_for_model("gpt-4")

        self.yt_url = yt_url
        self.api_key = api_key
        self.gpt_model = gpt_model

        self.messages = []

        self.video_id = extract.video_id(self.yt_url)
        self.title = self._fetch_title()
        self.transcript = self._get_edited_transcript()
        self._generate_question_from_title()

    def count_tokens(self, messages) -> int:
        """
        Counts the combined tokens of all messages in self.messages
        """
        count = 0
        for message in messages:
            count += len(self.tokenizer.encode(message["content"]))

        return count
    
    def split_transcript(self, transcript, max_len):
        """
        Split the transcript into parts so that the total tokens do not exceed max_len.

        Args:
            transcript (str): The transcript to split.
            max_len (int): The maximum allowed tokens in each part.

        Returns:
            list: A list of transcript parts.
        """
        parts = []
        words = transcript.split()
        current_part = []

        for word in words:
            current_part.append(word)
            if self.count_tokens(current_part) > max_len:
                current_part.pop()  # remove the last word that caused the overflow
                parts.append(' '.join(current_part))
                current_part = [word]  # start a new part with the current word

        # add the last part if it's non-empty
        if current_part:
            parts.append(' '.join(current_part))

        return parts

    def answer_title_question(self) -> None:
        """
        Generates an answer to the current question using OpenAI's GPT-3 language model.

        Returns:
            str: A string containing the answer to the current question.

        Raises:
            openai.error.OpenAIError: If there is an error while communicating with the OpenAI API.
        """

        answer_question_prompt = prompts.answer_question_prompt(self.transcript, self.question)
        self.messages.append({"role":"user", "content":answer_question_prompt})

        n_tokens = self.count_tokens(self.messages)
        if models_config.MAX_TOKENS_LARGE_MODEL > n_tokens > models_config.MAX_TOKENS_SMALL_MODEL:
            model = models_config.LARGE_MODEL
        elif n_tokens < models_config.MAX_TOKENS_SMALL_MODEL:
            model = models_config.SMALL_MODEL
        elif n_tokens > models_config.MAX_TOKENS_LARGE_MODEL: 
            n_tokens_convo = self.count_tokens(self.messages)
            max_transcript_len = models_config.MAX_TOKENS_LARGE_MODEL - n_tokens_convo

            self.messages.pop(-1)

            # split the transcript content into parts
            parts = self.split_transcript(self.transcript, max_transcript_len)

            summarized_parts = []

            for part in parts:
                # get short summary of the transcript part
                summary_msgs = []
                summary_msgs.append({"role":"system", "content":prompts.SUMMARIZE_INSTRUCTION})
                summary_msgs.append({"role": "user", "content": part})


                completion = openai.ChatCompletion.create(
                    model=model,
                    messages = summary_msgs
                )


                summarized_parts.append(completion['choices'][0]['message']['content'])
            
            # Log summary for verification
            self.logger.info(f"Summarized parts:\n{' '.join(summarized_parts)}")

            # Set the combined summarized parts as new last message
            answer_question_prompt = prompts.answer_question_prompt(self.transcript, self.question)

        
        completion = openai.ChatCompletion.create(
            model=model,
            messages = self.messages
        )

        return [completion['choices'][0]['message']['content']][0]

    def _generate_question_from_title(self) -> None:
        """
        Generates a question impliedby the video title using OpenAI's GPT-3 language model.

        Returns:
            str: A string containing the question.

        Raises:
            openai.error.OpenAIError: If there is an error while communicating with the OpenAI API.
        """
        self.messages.append({"role":"system", "content": prompts.question_from_title_prompt()})
        self.messages.append({"role":"user", "content":self.title})

        completion = openai.ChatCompletion.create(
            model=self.gpt_model,
            messages = self.messages
        )

        self.question = completion['choices'][0]['message']['content']

        self.logger.info(f"Generated question: {self.question}")
        

        self.messages.append({"role":"assistant", "content":self.question})

    def _fetch_title(self) -> str:
        """
        Fetches the title of a YouTube video using the YouTube API.

        Returns:
            str: A string containing the title of the video.
        """

        response = requests.get(
            f"https://www.youtube.com/oembed?url=https://www.youtube.com/watch?v={self.video_id}&format=json"
        )
        data = response.json()
        return data["title"]

    def _get_edited_transcript(self) -> str:
        """
        Retrieves the transcript for a YouTube video using the YouTubeTranscriptApi package.
        Pre-processes the transcript by stemming and removing stopwords.

        Returns:
            str: A string containing the formatted transcript of the video.
        """

        # Get transcript string
        tokenized_transcript = word_tokenize(
            TextFormatter()
            .format_transcript(YouTubeTranscriptApi.get_transcript(self.video_id))
            .replace("\n", " ")
            .replace("\xa0", " ")
        )

        # Stem transcript
        stemmed_transcript = [PorterStemmer().stem(word) for word in tokenized_transcript]

        return " ".join(stemmed_transcript)
