# move autogenerated files to a separate directory

import os
import shutil
from pathlib import Path
import re
import pycld2 as cld2
from guesslang import Guess
import tiktoken
import numpy as np


tokenizer = tiktoken.get_encoding('cl100k_base')


def find_autogen_markers(code):
    # Use regular expression to find auto-generated markers
    # per suggestion by Mark Chen from OpenAI
    autogen_patterns = [
        'all changes made in this file will be lost',
        'auto-generated',
        'created by makepy.py',
        'automatically generated',
        'chatgpt',
        'autogenerate',
        'generated by django',
        'commands auto generated',
        'code generated by'

    ]
    autogen_matches = [
        re.search(pattern, ' '.join(code).lower())
        for pattern in autogen_patterns
    ]
    return len([i for i in autogen_matches if i is not None]) > 0


def has_no_functions(code):
    pattern = r'def '
    nmatches = 0
    for line in code:
        matches = re.finditer(pattern, line)
        nmatches += len(list(matches))
    return nmatches == 0


def find_obfuscation(code):
    # Use regular expression to find x-x obfuscation patterns
    # per suggestion by Mark Chen from OpenAI
    pattern = r'if \b\d+\s*-\s*\d+\b:'
    nmatches = 0
    for line in code:
        matches = re.finditer(pattern, line)
        nmatches += len(list(matches))
    return nmatches


def detect_nonenglish(code):
    try:
        _, _, _, detected_language = cld2.detect(
            ' '.join(code), returnVectors=True
        )
    except Exception:
        return True, []
    nonenglish = [
        lang[2]
        for lang in detected_language
        if lang[2] not in ['ENGLISH', 'Unknown']
    ]
    return len(nonenglish) > 0, nonenglish


def guess_language(code):
    guess = Guess()
    return guess.language_name(' '.join(code))


def getTokenLength(code):
    tokens = tokenizer.encode(' '.join(code))
    return len(tokens)


def get_linelengths(code):
    ll = [len(line) for line in code]
    return np.mean(ll), np.max(ll)


if __name__ == '__main__':
    codedir = Path('data/github/code')
    outdir = Path('data/github/excluded')
    max_filesize = 1000000
    max_mean_line_length = 100
    max_max_line_length = 1000
    max_tokens = 2500
    min_tokens = 200

    if not outdir.exists():
        outdir.mkdir()

    for f in codedir.glob('*.py'):
        try:
            with open(f) as fh:
                code = fh.readlines()
            assert len(code) > 0
        except Exception:
            print(f'error reading {f}')
            shutil.move(f, os.path.join(outdir, f.as_posix().split('/')[-1]))
            continue
        meanll, maxll = get_linelengths(code)
        ntokens = getTokenLength(code)
        if find_autogen_markers(code) or has_no_functions(code) or find_obfuscation(code) > 100 or\
            detect_nonenglish(code)[0] or guess_language(code) != 'Python' or\
            os.path.getsize(f) > max_filesize or meanll > max_mean_line_length or\
            maxll > max_max_line_length or ntokens > max_tokens or ntokens < min_tokens:
            print(f)
            shutil.move(f, os.path.join(outdir, f.as_posix().split('/')[-1]))
