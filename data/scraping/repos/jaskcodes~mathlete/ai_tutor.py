from langchain.schema.messages import SystemMessage
from langchain.chat_models import ChatOpenAI
from langchain.schema import (
    AIMessage, # AI Input
    HumanMessage, # user input
    SystemMessage # sets the tone of the conversation
)
from langchain.evaluation.qa import QAEvalChain
import openai
from langchain.llms import OpenAI
from prompt import system_message, few_shot_examples

def generate_prompt(few_shot_examples=few_shot_examples, system_message=system_message):
    """
    Given few shot examples, and a system message to set the tone of the conversation,
    generate a prompt for the AI tutor

    Args:
        few_shot_examples (list, optional): examples using few shot prompting
        system_message (str, optional): A system message providing guidance to 
            the AI math tutor.
            Defaults to system_message defined elsewhere.

    Returns:
        list: A list of messages including the system message and user-generated examples
    """

    messages = [SystemMessage(content=system_message)]
    for example in few_shot_examples:
        user_message = example["question"]
        ai_message = example["answer"]
        messages.append(HumanMessage(content=user_message))
        messages.append(AIMessage(content=ai_message))
    return messages


def prompt_response(question, few_shot_examples=few_shot_examples, system_message=system_message):
    """ Ask a question to the AI tutor
    
    Args:
        question (string): An elementary math question
        few_shot_examples (list, optional): examples used to train the tutor
        system_message (str, optional): System message used to train the tutor
    
    Returns:
        AI Tutor's response to the question
    """
    chat = ChatOpenAI(temperature=0)
    messages = generate_prompt(few_shot_examples, system_message)
    messages.append(HumanMessage(content=question))
    return chat(messages).content

def interactive_session():
    """
    Start an interactive session with the tutor
    """
    chat = ChatOpenAI(temperature=0,
                    max_tokens=1000)
    messages = generate_prompt()
    
    while True:
      user_message = input("You: ")
      messages.append(HumanMessage(content=user_message))
      if user_message.lower() == "quit":
        break
      response = chat(messages)
      messages.append(response)

      print("\nAI:", response.content)


def evaluate_math_tutor(questions_df):
    """
    Function to evaluate the answers generated by the tutor

    Args:
        questions_df (pandas.DataFrame): DataFrame containing the questions 
                                         and correct answers. Each row in the 
                                         DataFrame should represent one 
                                         question and corresponding answer.

    Returns:
        list: Returns a list of dictionaries containing the results of the 
              evaluation. Each dictionary contains the question, answer, 
              and result of evaluation (e.g. 'correct', 'incorrect').
    """
    predictions = []
    for n in range(len(questions_df)):
        question = questions_df[n]['question']
        answer = prompt_response(question)
        predictions.append({'text': answer})
    llm = OpenAI(temperature=0)

    eval_chain = QAEvalChain.from_llm(llm)
    graded_outputs = eval_chain.evaluate(questions_df, predictions, question_key='question',
                                         answer_key='answer', prediction_key='text')

    return graded_outputs

def analyze_results(results):
    """
    Computes and returns the accuracy of AI tutor based on the evaluation results.
    
    Args:
        results (list): List of dictionaries with keys 'results' denoting the correctness of the response.

    Returns:
        str: A string expressing the AI tutor's accuracy as a percentage.
    """ 

    total, correct, idx=0,0,0
    for v in results: # loop to compute accuracy
        total+=1; idx+=1
        if v['results'].strip()=='CORRECT':
            correct+=1

    return f'the model prediction accuracy is {correct/total*100} percent'
