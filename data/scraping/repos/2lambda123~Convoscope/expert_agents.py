#langchain
from langchain.chat_models import ChatOpenAI
from langchain.agents.tools import Tool
from langchain.agents import initialize_agent
from langchain.agents import AgentType
from pydantic import BaseModel, Field, validator
from langchain.output_parsers import PydanticOutputParser
from langchain.schema import OutputParserException
from constants import GPT_4_MODEL, GPT_4_MAX_TOKENS, GPT_TEMPERATURE

#custom
from server_config import openai_api_key
from agents.expert_agent_configs import expert_agent_config_list, expert_agent_prompt_maker
from agents.search_tool_for_agents import get_search_tool_for_agents
from agents.math_tool_for_agents import get_wolfram_alpha_tool_for_agents

#agent insight structure
class AgentInsight(BaseModel):
        """
        Query for an insight generation process
        """
        agent_insight: str = Field(
             description="the short insight generated by the agent", default="null")
        reference_url: str = Field(
             description="the url of the most relevant reference used to generate this insight", default="")
        agent_motive: str = Field(
             description="short motive of why the insight was generated, quoting the text from the transcript", default="")


agent_insight_parser = PydanticOutputParser(pydantic_object=AgentInsight)

#start up the agent blueprint
llm = ChatOpenAI(temperature=GPT_TEMPERATURE, openai_api_key=openai_api_key, model=GPT_4_MODEL, max_tokens=GPT_4_MAX_TOKENS)
agent = initialize_agent([
        get_search_tool_for_agents(),
        get_wolfram_alpha_tool_for_agents(),
    ], llm, agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, max_iterations=3, early_stopping_method="generate", verbose=True)

def post_process_agent_output(expert_agent_response, agent_name):
    #agent output should be like
    #{"agent_insight": "null" | "insight", "reference_url": "https://..." | "", "agent_motive": "because ..." | ""}
    
    try:
        #handle null response
        if expert_agent_response is None or expert_agent_response == "null":
            return None
        
        #response is already a dict from langchain internals
        #but we want to check again, so we stringify the response and parse
        #we need to parse this way because str replaces the double quotes with single quotes
        str_response = "{"
        for k,v in expert_agent_response.items():
            v = v.replace('"', '')
            str_response += f'"{k}": "{v}", '
        str_response = str_response[:-2] + "}"

        expert_agent_response = agent_insight_parser.parse(str_response)
        expert_agent_response = expert_agent_response.dict()

        #clean insight
        agent_insight = expert_agent_response["agent_insight"]

        # handle null insight
        if "null" in agent_insight:
            return None
        
        #remove "Insight: " preface from insight
        expert_agent_response["agent_insight"] = agent_insight.replace("Insight: ", "")

        # add agent name to the json obj
        expert_agent_response["agent_name"] = agent_name

        return expert_agent_response
    
    except OutputParserException as e:
        print(e)
        return None


def run_single_expert_agent(expert_agent_name, convo_context, insights_history: list):
    #initialize the requested expert agent - using the name given
    expert_agent_config = expert_agent_config_list[expert_agent_name]

    #run the agent
    expert_agent_response = expert_agent_run_wrapper(expert_agent_config, convo_context, insights_history)
    if expert_agent_response is None:
        return None

    #process the output
    expert_agent_response = post_process_agent_output(expert_agent_response, expert_agent_name)
    return expert_agent_response


async def arun_single_expert_agent(expert_agent_name, convo_context, insights_history: list):
    #initialize the requested expert agent - using the name given
    expert_agent_config = expert_agent_config_list[expert_agent_name]

    #run the agent
    expert_agent_response = await expert_agent_arun_wrapper(expert_agent_config, convo_context, insights_history)
    print(expert_agent_response)
    if expert_agent_response is None:
        return None

    #process the output
    expert_agent_response = post_process_agent_output(expert_agent_response, expert_agent_name)
    return expert_agent_response


async def expert_agent_arun_wrapper(expert_agent_config, convo_context, insights_history: list):
    #get agent response
    expert_agent_response = await agent.arun(expert_agent_prompt_maker(expert_agent_config, convo_context, format_instructions=agent_insight_parser.get_format_instructions(), insights_history=insights_history))
    if expert_agent_response is None:
        return None

    #post process the output
    expert_agent_response = post_process_agent_output(expert_agent_response, expert_agent_config["agent_name"])

    print("expert_agent_response", expert_agent_response)
    
    return expert_agent_response
    

def expert_agent_run_wrapper(expert_agent_config, convo_context, insights_history: list):
    #run the agent
    expert_agent_response = agent.run(expert_agent_prompt_maker(expert_agent_config, convo_context, format_instructions=agent_insight_parser.get_format_instructions(), insights_history=insights_history))
    if expert_agent_response is None:
        return None

    #post process the output
    expert_agent_response = post_process_agent_output(expert_agent_response, expert_agent_config["agent_name"])

    print("expert_agent_response", expert_agent_response)

    return expert_agent_response

