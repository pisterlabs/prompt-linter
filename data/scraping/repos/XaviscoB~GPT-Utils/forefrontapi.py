"""Wrapper around ForeFront APIs."""
from typing import Any, Dict, List, Optional

import requests
from pydantic import BaseModel, Extra

from models.forefront.model import Model
from langchain.callbacks.manager import CallbackManagerForLLMRun
from langchain.llms.base import LLM

class ForeFront(LLM):
    """Wrapper around ForeFront large language models.

    To use, you should have the environment variable ``AI21_API_KEY``
    set with your API key.

    Example:
        .. code-block:: python

            from langchain.llms import AI21
            ai21 = AI21(model="j2-jumbo-instruct")
    """

    client: Optional[str]

    session: Optional[str]

    model: str = "j2-jumbo-instruct"
    """Model name to use."""

    numResults: int = 1
    """How many completions to generate for each prompt."""

    logitBias: Optional[Dict[str, float]] = None
    """Adjust the probability of specific tokens being generated."""

    stop: Optional[List[str]] = None

    base_url: Optional[str] = None
    """Base url to use, if None decides based on model name."""

    class Config:
        """Configuration for this pydantic object."""

        extra = Extra.forbid

    @property
    def _identifying_params(self) -> Dict[str, Any]:
        """Get the identifying parameters."""
        return {**{"model": self.model}, **self._default_params}

    @property
    def _llm_type(self) -> str:
        """Return type of llm."""
        return "ai21"

    def _call(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
    ) -> str:
        """Call out to ForeFront's complete endpoint.

        Args:
            prompt: The prompt to pass into the model.
            stop: Optional list of stop words to use when generating.

        Returns:
            The string generated by the model.

        Example:
            .. code-block:: python

                response = ai21("Tell me a joke.")
        """
        if self.stop is not None and stop is not None:
            raise ValueError("`stop` found in both the input and default params.")
        elif self.stop is not None:
            stop = self.stop
        elif stop is None:
            stop = []
        if self.base_url is not None:
            base_url = self.base_url
        else:
            if self.model in ("j1-grande-instruct",):
                base_url = "https://api.ai21.com/studio/v1/experimental"
            else:
                base_url = "https://api.ai21.com/studio/v1"
        forefront = Model(sessionID=self.session, client=self.client, model="gpt-3.5-turbo")
        forefront.SetupConversation(prompt=prompt, options={"create": True, "name": "LangChain" + "Chat"})
        obj = []
        print("FALA FIOTE")
        for r in forefront.SendConversation():
            print(r.choices[0].delta.content)
            obj.append(r.choices[0].delta.content)
        obj_str = ''.join(obj)
        return obj_str