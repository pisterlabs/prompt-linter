# Do the below in supabase
# create table public.document_embeds_openai(id bigint generated by default as identity not null,
# content text null,
# sources text null,
# embedding vector(1536) null,
# metadata jsonb null,
# constraint document_embeds_open_pkey primary key(id) ) tablespace pg_default;

# Also create the below function in supabase

# create or replace function match_documents_chain_embeds( query_embedding vector(768),
#                                                          match_thresholdfloat,match_count int)
# returns table(id bigint, sources text,content text, similarity float, metadata jsonb)
# language
# sql stable
# as $$
# select
# document_embeds_openai.id,
# document_embeds_openai.sources,
# document_embeds_openai.content,
# 1 - (document_embeds_openai.embedding <= > query_embedding) as similarity,
# metadata from document_embeds_openai where
# 1 - (document_embeds_openai.embedding <= > query_embedding) > match_threshold
# order by similarity desc limit match_count;
# $$;

import os
from typing import List

from dotenv import load_dotenv
from langchain import OpenAI
from langchain.schema import Document
from supabase import Client, create_client

from embeddings.openaiembeddings import OpenAIEmbeds
from llm_prompt_template.example_template01 import ExampleTemplate01
from llm_prompt_template.load_qa_prompt_template import LoadQATemplate

load_dotenv()

OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')

def get_context() -> List[Document]:
    documents = [Document(
            page_content="Men's football match will be hosted on 9th march",
            metadata={}),
        Document(
            page_content="Women's football match will be hosted on 8th march",
            metadata={}),
        Document(
            page_content="wheelchair basketball camp will be hosted on 8th march",
            metadata={})
    ]

    return documents

if __name__=="__main__":

    llm = OpenAI(model_name="text-davinci-003",
                     openai_api_key=OPENAI_API_KEY,
                     temperature=0,
                     max_tokens=1000)

    from langchain.chains.question_answering import load_qa_chain
    query = "Tell me about the sport events happening on 8th March"
    docs = get_context()
    prompt_template = ExampleTemplate01()
    prompt = prompt_template.get_prompt()
    chain = load_qa_chain(llm, chain_type="stuff",prompt=prompt)
    resp = chain.run(input_documents=docs, question=query)

    print(resp)