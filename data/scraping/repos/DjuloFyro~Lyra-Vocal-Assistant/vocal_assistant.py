import speech_recognition as sr
import os
from langchain import OpenAI, LLMChain, PromptTemplate
from langchain.tools import Tool
from langchain.utilities import GoogleSearchAPIWrapper
from playsound import playsound
from google.cloud import texttospeech
from pydub import AudioSegment
from pydub.playback import play



GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY")

class VocalAssistant:
    """
    Class representing a vocal assistant.

    Attributes:
        OPENAI_API_KEY (str): API key for OpenAI.
        template (str): Template for the assistant's response.
    """

    def __init__(self):
        self.OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
        self.template = """
        L'Assistant est un outil puissant qui peut vous aider dans une grande variété de tâches et vous fournir des informations précieuses sur un large éventail de sujets. Que vous ayez besoin d'aide pour une question spécifique ou que vous souhaitiez simplement avoir une conversation sur un sujet particulier, l'Assistant est là pour vous aider.

        L'Assistant est conscient que l'entrée humaine est transcrite à partir de l'audio et, en conséquence, il peut y avoir quelques erreurs dans la transcription. Il tentera de tenir compte du fait que certains mots peuvent être échangés avec des mots ou des phrases qui se ressemblent. L'Assistant répondra également de manière concise, car l'attention humaine est plus limitée lorsqu'il s'agit d'audio, car il faut du temps pour écouter une réponse.

        Humain : {input}

        Informations provenant d'Internet, que vous pouvez utiliser si vous estimez que c'est nécessaire : {internet_search}
        
        L'assistant doit toujours repondre en francais.
        Assistant:
        """

    def listen(self) -> str:
        """
        Listens to audio input from the user.

        Returns:
            str: Transcribed text from the audio.
        """
        r = sr.Recognizer()
        with sr.Microphone() as source:
            r.adjust_for_ambient_noise(source, duration=5)
            print("TING TING")
            output_file = "dis_moi.wav"
            audio = AudioSegment.from_wav(output_file)
            play(audio)
            audio = r.listen(source, timeout=5, phrase_time_limit=30)
        try:
            return r.recognize_google(audio, language='fr-FR')
        except sr.UnknownValueError:
            print("Could not understand audio")
        except sr.RequestError as e:
            print("Could not request results from Whisper API")

        return ""

    def think(self, input_text: str) -> str:
        """
        Processes the input text and generates a response.

        Args:
            input_text (str): Input text from the user.

        Returns:
            str: Response generated by the assistant.
        """
        prompt = PromptTemplate(input_variables=['input', 'internet_search'], template=self.template)

        # Search on the internet
        search = GoogleSearchAPIWrapper(k=2)
        tool = Tool(
            name="Google Search",
            description="Search Google for recent results.",
            func=search.run,
        )
        internet_response = tool.run(input_text)

        chat_chain = LLMChain(
            llm=OpenAI(temperature=0),
            prompt=prompt,
            verbose=True,
        )
        response = chat_chain.predict(input=input_text, internet_search=internet_response)
        return response

    def speak(self, audio: str) -> None:
        """
        Converts the generated audio to speech and plays it.

        Args:
            audio (str): Audio to be converted to speech.
        """
        # Create a Text-to-Speech client
        client = texttospeech.TextToSpeechClient()


        # Specify the voice to use
        voice = texttospeech.VoiceSelectionParams(
            language_code="fr-FR",
            name="fr-FR-Standard-A",
        )

        # Specify the audio configuration
        audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.LINEAR16
        )

        # Generate the synthesis request
        synthesis_input = texttospeech.SynthesisInput(text=audio)
        response = client.synthesize_speech(
            input=synthesis_input, voice=voice, audio_config=audio_config
        )

        # Save the audio to a file
        output_file = "output.wav"
        with open(output_file, "wb") as out_file:
            out_file.write(response.audio_content)

        audio = AudioSegment.from_wav(output_file)
        play(audio)
