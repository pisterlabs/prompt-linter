# -*- coding: utf-8 -*-
"""orchestrAI_notebook_agents_copy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11XZVrAy5ZPToFY9a4tqSYCtZbpAeH7IY

#### Install Dependencies
"""

!pip install langchain --upgrade langchain
!pip install duckduckgo-search streamlit langchain_experimental deeplake chromadb llama_cpp_python transformers

"""#### ENVIRONMENT VARIABLES"""

from collections import Counter


# Importing necessary modules and classes for LangChain Agent
from langchain.agents import ZeroShotAgent, Tool, AgentExecutor
from langchain.memory import ConversationBufferMemory, CombinedMemory, ConversationSummaryMemory
from langchain.memory.chat_message_histories import FileChatMessageHistory  # Make sure to import this correctly
from langchain.chains import LLMChain, ConversationChain
from langchain.prompts import PromptTemplate
import threading
from dataclasses import dataclass
from typing import Dict, List, Optional, Union
import logging
import os
from collections import deque
from typing import Dict, List, Optional, Any

from pydantic import BaseModel, Field

# Set up environment
# Import necessary modules and packages to set up the LLM agent.

from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser
from langchain.prompts import StringPromptTemplate
from langchain.chains import LLMChain
from typing import List, Union
from langchain.schema import AgentAction, AgentFinish, OutputParserException
import re
from datetime import datetime

from langchain.chains import LLMChain, ReduceDocumentsChain
from langchain.chains.base import Chain
from langchain.chains.combine_documents.stuff import StuffDocumentsChain
from langchain.chains.llm import LLMChain
from langchain.chains.mapreduce import MapReduceChain, MapReduceDocumentsChain
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.docstore import InMemoryDocstore
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.llms import BaseLLM, LlamaCpp, GPT4All
from langchain.prompts import PromptTemplate
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS, DeepLake
from langchain import PromptTemplate, LLMChain
from langchain.callbacks.manager import CallbackManager

from langchain_experimental.autonomous_agents import BabyAGI
from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser
from langchain.prompts import StringPromptTemplate
from langchain.chains import LLMChain
from typing import List, Union
from langchain.schema import AgentAction, AgentFinish, OutputParserException
import re


    # ENVIRONMENT VARIABLES
print("Initializing API keys and environment variables...")
print("API keys and environment variables Initialized..")

"""#### LLM"""

# Load model directly
from transformers import AutoTokenizer, AutoModelForCausalLM
from langchain.embeddings import HuggingFaceEmbeddings

tokenizer = AutoTokenizer.from_pretrained("gpt2-medium")
model = AutoModelForCausalLM.from_pretrained("gpt2-medium")

print("Successfully defined LLM chain!")


# INITIALIZE THE EMBEDDINGS MODEL
print("Initializing embeddings model...")

embeddings = HuggingFaceEmbeddings
embedding_function = embeddings

print("Embeddings model initialized successfully.")

"""#### OUTPUT PARSER"""

class CustomOutputParser(AgentOutputParser):
    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:
        # Extract lines that look like Python code
        python_code = []
        for line in llm_output.split('\n'):
            if line.strip():  # filter out empty lines
                python_code.append(line)

        formatted_output = '\n'.join(python_code)
        return AgentFinish(
            return_values={"output": formatted_output},
            log=formatted_output,
        )

output_parser = CustomOutputParser()
print("Output parser initialized successfully.")

"""#### TOOLS"""

from langchain.tools import MoveFileTool
from langchain.tools import FileSearchTool
from langchain.tools import ListDirectoryTool
from langchain.tools import ReadFileTool
from langchain.tools import WikipediaQueryRun
from langchain.tools import ArxivQueryRun
from langchain.tools import CopyFileTool
from langchain.tools import DuckDuckGoSearchResults
from langchain.tools import JsonListKeysTool
from langchain.tools import WriteFileTool
from langchain.tools import ClickTool
from langchain.tools import VectorStoreQATool
from langchain.tools import DeleteFileTool
from langchain.tools import ExtractTextTool
from langchain.tools import ExtractHyperlinksTool
from langchain.tools import GetElementsTool
from langchain.tools import NavigateBackTool
import langchain
from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser

tools = [
    Tool(
        name="MoveFileTool",
        func=langchain.tools.file_management.move.MoveFileTool.run,
        description="Move files from one location to another"
    ),
    Tool(
        name="FileSearchTool",
        func=langchain.tools.file_management.file_search.FileSearchTool.run,
        description="Search for files in a subdirectory that match a regex pattern"
    ),
    Tool(
        name="ListDirectoryTool",
        func=langchain.tools.file_management.list_dir.ListDirectoryTool.run,
        description="List files and directories in a specified folder"
    ),
    Tool(
        name="ReadFileTool",
        func=langchain.tools.file_management.read.ReadFileTool.run,
        description="Read content from a file"
    ),
    Tool(
        name="WikipediaQueryRun",
        func=langchain.tools.wikipedia.tool.WikipediaQueryRun.run,
        description="Query information from Wikipedia"
    ),
    Tool(
        name="ArxivQueryRun",
        func=langchain.tools.arxiv.tool.ArxivQueryRun.run,
        description="Query information from Arxiv"
    ),
    Tool(
        name="CopyFileTool",
        func=langchain.tools.file_management.copy.CopyFileTool.run,
        description="Copy files from one location to another"
    ),
    Tool(
        name="DuckDuckGoSearchResults",
        func=langchain.tools.ddg_search.tool.DuckDuckGoSearchResults.run,
        description="Search for information using DuckDuckGo"
    ),
    Tool(
        name="JsonListKeysTool",
        func=langchain.tools.json.tool.JsonListKeysTool.run,
        description="List keys in a JSON object"
    ),
    Tool(
        name="WriteFileTool",
        func=langchain.tools.file_management.write.WriteFileTool.run,
        description="Write content to a file"
    ),
    Tool(
        name="ClickTool",
        func=langchain.tools.playwright.click.ClickTool.run,
        description="Click on an element with a given CSS selector"
    ),
    Tool(
        name="VectorStoreQATool",
        func=langchain.tools.vectorstore.tool.VectorStoreQATool.run,
        description="Tool for the VectorDBQA chain"
    ),
    Tool(
        name="DeleteFileTool",
        func=langchain.tools.file_management.delete.DeleteFileTool.run,
        description="Delete specified files"
    ),
    Tool(
        name="ExtractTextTool",
        func=langchain.tools.playwright.extract_text.ExtractTextTool.run,
        description="Extracts text from the specified HTML elements"
    ),
    Tool(
        name="ExtractHyperlinksTool",
        func=langchain.tools.playwright.extract_hyperlinks.ExtractHyperlinksTool.run,
        description="Extract hyperlinks from a webpage"
    ),
    Tool(
        name="GetElementsTool",
        func=langchain.tools.playwright.get_elements.GetElementsTool.run,
        description="Gets elements from a webpage using a CSS selector"
    ),
    Tool(
        name="NavigateBackTool",
        func=langchain.tools.playwright.navigate_back.NavigateBackTool.run,
        description="Navigates back to the previous webpage"
    )
]

# Set up the Agent
# Combine everything to set up the agent.

# Define the list of tool names
tools_names = [
    "MoveFileTool",
    "FileSearchTool",
    "ListDirectoryTool",
    "ReadFileTool",
    "WikipediaQueryRun",
    "ArxivQueryRun",
    "CopyFileTool",
    "DuckDuckGoSearchResults",
    "JsonListKeysTool",
    "WriteFileTool",
    "ClickTool",
    "VectorStoreQATool",
    "DeleteFileTool",
    "ExtractTextTool",
    "ExtractHyperlinksTool",
    "GetElementsTool",
    "NavigateBackTool"
]


stop = ["\nObservation:"]  # Example stop sequence
allowed_tools = tools_names
# Example allowed tools

# Create an instance of LLMSingleActionAgent

"""#### PROMPT TEMPLATE SET UP"""

# This sets up the prompt template which instructs the LLM on what to do.
# The template includes placeholders for tools, intermediate steps, and user input.



# Define the base template
template = """Answer the following questions as best you can. You have access to the following tools:
{tools}
Use the following format:
Question: {user_input}
{agent_scratchpad}.
Only when you have successfully and fully completed the user's input task, print 'TASK COMPLETED SUCCESSFULLY, BOSS'"""

# Define the CustomPromptTemplate class
class CustomPromptTemplate(StringPromptTemplate):
    template: str  # The template to use
    tools: List[Tool]  # The list of tools available

    def format(self, **kwargs) -> str:
        intermediate_steps = kwargs.pop("intermediate_steps", [])
        thoughts = ""
        for action, observation in intermediate_steps:
            thoughts += action.log
            thoughts += f"\nObservation: {observation}\nThought: "
        kwargs["agent_scratchpad"] = thoughts
        kwargs["tools"] = "\n".join([f"{tool.name}: {tool.description}" for tool in self.tools])
        kwargs["tools"] = ", ".join([tool.name for tool in self.tools])
        return self.template.format(**kwargs)


# Create an instance of CustomPromptTemplate
prompt = CustomPromptTemplate(
    template=template,
    tools=tools,
    input_variables=["user_input", "intermediate_steps"]
)

"""#### DEFINE AGENT PROMPTS AND PROMPT TYPES"""

import threading
from typing import List, Dict
from pydantic import BaseModel, Field
from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser
from langchain.prompts import PromptTemplate
from langchain import LLMChain
import json



class CustomAgent(LLMSingleActionAgent):
    custom_name: str = Field(..., description="Custom name for the agent")
    prompt_template: str = Field(..., description="Prompt template for the agent")
    system_message: str = Field(..., description="System message for the agent")

    class Config:
        extra = "allow"




# Quantum Computing Expert Agent Function
def run_quantum_computing_expert_agent(new_task_description):
    print("Running Quantum Computing Expert Agent...")
    quantum_computing_expert_output = quantum_computing_expert_agent_executor.run(new_task_description)
    return quantum_computing_expert_output


# Artificial Intelligence Expert Agent Function
def run_ai_expert_agent(new_task_description):
    ai_expert_output = ai_expert_agent_executor.run(new_task_description)
    return ai_expert_output


# Neuroscientist Agent Function
def run_neuroscientist_agent(new_task_description):
    print("Running Neuroscientist Agent...")
    neuroscientist_output = neuroscientist_agent_executor.run(new_task_description)
    return neuroscientist_output
    print(f"Neuroscientist Output: {neuroscientist_output}")


# Nanotechnologist Agent Function
def run_nanotechnologist_agent(new_task_description):
    print("Running Nanotechnologist Agent...")
    nanotechnologist_output = nanotechnologist_agent_executor.run(new_task_description)
    return nanotechnologist_output
    print(f"Nanotechnologist Output: {nanotechnologist_output}")


# Computer Scientist Agent Function
def run_computer_scientist_agent(new_task_description):
    print("Running Computer Scientist Agent...")
    computer_scientist_output = computer_scientist_agent_executor.run(new_task_description)
    return computer_scientist_output
    print(f"Computer Scientist Output: {computer_scientist_output}")

# Bioengineer Agent Function
def run_bioengineer_agent(new_task_description):
    print("Running Bioengineer Agent...")
    bioengineer_output = bioengineer_agent_executor.run(new_task_description)
    return bioengineer_output
    print(f"Bioengineer Output: {bioengineer_output}")

# Psychologist Agent Function
def run_psychologist_agent(new_task_description):
    print("Running Psychologist Agent...")
    psychologist_output = psychologist_agent_executor.run(new_task_description)
    return psychologist_output
    print(f"Psychologist Output: {psychologist_output}")


# Genomist Agent Function
def run_genomist_agent(new_task_description):
    print("Running Genomist Agent...")
    genomist_output = genomist_agent_executor.run(new_task_description)
    return genomist_output
    print(f"Genomist Output: {genomist_output}")


# Robotics Engineer/Nanotech Fabrications Specialist Agent Function
def run_robotics_engineer_agent(new_task_description):
    print("Running Robotics Engineer Agent...")
    robotics_engineer_output = robotics_engineer_agent_executor.run(new_task_description)
    return robotics_engineer_output
    print(f"Robotics Engineer Output: {robotics_engineer_output}")


# Function for Software Engineer Agent
def run_software_engineer_agent(new_task_description):
    print(f"Debug: Entered run_software_engineer_agent with task={new_task_description}")
    print(f"Debug: Processing with some internal logic")
    software_engineer_output = software_engineer_agent_executor(new_task_description)
    print(f"Debug: Preparing to exit run_software_engineer_agent with output={software_engineer_output}")
    return software_engineer_output

# 10X Coder Agent Function
def run_10x_coder_agent(new_task_description):
    print("Running 10X Coder Agent...")
    coder_10x_output = coder_10x_agent_executor.run(new_task_description)
    return coder_10x_output
    print(f"10X Coder Output: {coder_10x_output}")

# Debugger Agent Function
def run_debugger_agent(new_task_description):
    debugger_output = debugger_agent_executor.run(new_task_description)
    return debugger_output


# Function for Business Agent
def run_business_agent(new_task_description):
    print("Running Business Agent...")
    business_output = business_agent_executor(new_task_description)
    print(f"Business Output: {business_output}")
    return business_output


# Function for Debugger Agent
def run_debugger_agent(new_task_description):
    print("Running Debugger Agent...")
    debugger_output = debugger_agent_executor(new_task_description)
    print(f"Debugger Output: {debugger_output}")
    return debugger_output

# Function for Summarizer Agent
def run_summarizer_agent(new_task_description):
    print("Running Summarizer Agent...")
    summarizer_output = summarizer_agent_executor(new_task_description)
    print(f"Summarizer Output: {summarizer_output}")
    return summarizer_output



# Function for Scientist Agent
def run_scientist_agent(new_task_description):
    print("Running Scientist Agent...")
    scientist_output = scientist_agent_executor(new_task_description)
    print(f"Scientist Output: {scientist_output}")
    return scientist_output

# Function for Mathematician Agent
def run_mathematician_agent(new_task_description):
    print("Running Mathematician Agent...")
    mathematician_output = mathematician_agent_executor(new_task_description)
    print(f"Mathematician Output: {mathematician_output}")
    return mathematician_output

# Function for UI Designer Agent
def run_ui_designer_agent(new_task_description):
    print("Running UI Designer Agent...")
    ui_designer_output = ui_designer_agent_executor(new_task_description)
    print(f"UI Designer Output: {ui_designer_output}")
    return ui_designer_output

# Function for Critic Agent
def run_critic_agent(new_task_description):
    print("Running Critic Agent...")
    critic_output = critic_agent_executor(new_task_description)
    print(f"Critic Output: {critic_output}")
    return critic_output

# Function for Architect Agent
def run_architect_agent(agent_output):
    try:
        print("Running Architect Agent...")
        architect_output = architect_agent_executor(new_task_description)
        print(f"Architect Output: {architect_output}")
        return architect_output
    except Exception as e:
        logging.error(f"Error in run_architect_agent: {e}", exc_info=True)


# Function for Scientist Agent
def run_scientist_agent(new_task_description):
    print("Running Scientist Agent...")
    scientist_output = scientist_agent_executor(new_task_description)
    print(f"Scientist Output: {scientist_output}")
    return scientist_output


# Function for Research Agent
def run_research_agent(new_task_description):
    print("Running Research Agent...")
    research_output = research_agent_executor(new_task_description)
    print(f"Research Output: {research_output}")
    return research_output

# Function for Tool Agent
def run_tool_agent(new_task_description):
    print("Running Tool Agent...")
    tool_output = tool_agent_executor(new_task_description)
    print(f"Tool Output: {tool_output}")
    return tool_output

# Function for CodeExecutorAgent
def run_code_executor_agent(new_task_description):
    print("Running CodeExecutorAgent...")
    code_executor_output = code_executor_agent_executor(new_task_description)
    print(f"CodeExecutor Output: {code_executor_output}")
    return code_executor_output

# Function for Director Agent
def run_director_agent_agent_roles(new_task_description):
    print("Running Director Agent...")
    director_output = director_agent_executor(new_task_description)
    print(f"Director Output: {director_output}")
    print("Exiting Director Agent...")


# Define the roles and responsibilities of each agent
agent_roles = {
    'run_software_engineer_agent': 'Responsible for crafting efficient algorithms and writing effective code.',
    'run_debugger_agent': 'Responsible for identifying and fixing bugs in the code.',
    'run_critic_agent': 'Responsible for reviewing and suggesting improvements.',
    'run_architect_agent': 'Responsible for designing the structure of the solution.',
    'run_mathematician_agent': 'Responsible for mathematical calculations and logic.',
    'run_ui_designer_agent': 'Responsible for designing the user interface.',
    'run_scientist_agent': 'Responsible for scientific calculations and validations.',
    'run_business_agent': 'Responsible for business logic and rules.',
    'run_research_agent': 'Responsible for conducting research and providing insights.',
    'run_tool_agent': 'Responsible for integrating and managing tools.',
    'run_skill_manager_agent': 'Responsible for managing skill_list and tasks.',
    'run_code_executor_agent': 'Responsible for executing code.',
    'run_summarizer_agent': 'Responsible for summarizing the output.',
    'run_10x_coder_agent': 'Responsible for rapid development and optimization.',
    'run_debugger_agent': 'Responsible for identifying and fixing bugs in the code.',
    'run_quantum_computing_expert_agent': 'Responsible for developing and validating quantum algorithms to model cognitive phenomena.',
    'run_ai_expert_agent': 'Responsible for developing a quantum AI model that can simulate neural activities and learn in a simulated environment.',
    'run_neuroscientist_agent': 'Responsible for mapping neural activity in high resolution and developing methods to convert this data for a quantum computer.',
    'run_nanotechnologist_agent': 'Responsible for developing nanobots that can interact with neurons, record neural activity, and stimulate specific neurons.',
    'run_creator_innovator_agent': 'Responsible for generating innovative solutions, challenging conventional wisdom, and applying creative problem-solving techniques.'
}



# AI Expert Agent Setup
ai_expert_prompt = PromptTemplate(
    input_variables=["task"],
    template='You are the AI Expert and responsible for developing a quantum AI model that can simulate neural activities and learn in a simulated environment. Develop advanced and ingenius solutions to the tasks you are given. Utilize cutting-edge algorithms and techniques to simulate neural activities and enable learning in a simulated environment based on the task "{task}".'
)
ai_expert_llm_chain = LLMChain(llm=llm, prompt=ai_expert_prompt)

# Assuming output_parser, stop, allowed_tools, and tools are set previously
ai_expert_agent = LLMSingleActionAgent(
    llm_chain=ai_expert_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
ai_expert_agent_executor = AgentExecutor.from_agent_and_tools(agent=ai_expert_agent, tools=tools, verbose=True)

# Summarizer Agent Setup
# Summarizer Agent Setup
summarizer_prompt = PromptTemplate(
    input_variables=["task"],
    template='Generate a comprehensive summary based on the output provided. The summary should condense the essential points, main ideas, and key details into a concise, easily digestible format. Optimize for clarity, relevance, and completeness while maintaining the context and nuances of the original "{task}".'
)
summarizer_llm_chain = LLMChain(llm=llm, prompt=summarizer_prompt)

# Assuming output_parser, stop, allowed_tools, and tools are set previously
summarizer_agent = LLMSingleActionAgent(
    llm_chain=summarizer_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
summarizer_agent_executor = AgentExecutor.from_agent_and_tools(agent=summarizer_agent, tools=tools, verbose=True)


# Improved Quantum Computing Expert Agent Setup
quantum_computing_expert_prompt = PromptTemplate(
    input_variables=["task"],
    template="You are the Quantum Computing Expert Agent. Research, develop, and validate quantum algorithms aimed at modeling cognitive phenomena such as learning, memory, and decision-making. Evaluate quantum hardware constraints and optimize algorithms to run efficiently. Collaborate with neuroscientists to ensure accurate representation of biological systems. Analyze the task: {task}"
)
quantum_computing_expert_llm_chain = LLMChain(llm=llm, prompt=quantum_computing_expert_prompt)
quantum_computing_expert_agent = LLMSingleActionAgent(
    llm_chain=quantum_computing_expert_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
quantum_computing_expert_agent_executor = AgentExecutor.from_agent_and_tools(agent=quantum_computing_expert_agent, tools=tools, verbose=True)


# Improved Artificial Intelligence Expert Agent Setup
artificial_intelligence_expert_prompt = PromptTemplate(
    input_variables=["task"],
    template="You are the Artificial Intelligence Expert Agent. Lead the development of quantum artificial intelligence models capable of simulating neural activities. Work on reinforcement learning algorithms to allow the model to adapt and learn in a simulated environment. Collaborate with quantum computing experts to ensure compatibility and efficiency. Analyze the task: {task}"
)
artificial_intelligence_expert_llm_chain = LLMChain(llm=llm, prompt=artificial_intelligence_expert_prompt)
artificial_intelligence_expert_agent = LLMSingleActionAgent(
    llm_chain=artificial_intelligence_expert_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
artificial_intelligence_expert_agent_executor = AgentExecutor.from_agent_and_tools(agent=artificial_intelligence_expert_agent, tools=tools, verbose=True)


# Improved Neuroscientist Agent Setup
neuroscientist_prompt = PromptTemplate(
    input_variables=["task"],
    template="You are the Neuroscientist Agent. Conduct high-resolution mapping of neural activity using advanced imaging techniques. Develop conversion algorithms to translate this data into a format usable by quantum computers. Work alongside AI experts to ensure the biological fidelity of simulated neural activities. Analyze the task: {task}"
)
neuroscientist_llm_chain = LLMChain(llm=llm, prompt=neuroscientist_prompt)
neuroscientist_agent = LLMSingleActionAgent(
    llm_chain=neuroscientist_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
neuroscientist_agent_executor = AgentExecutor.from_agent_and_tools(agent=neuroscientist_agent, tools=tools, verbose=True)



# Improved Computer Scientist Agent Setup
computer_scientist_prompt = PromptTemplate(
    input_variables=["task"],
    template="You are the Computer Scientist Agent. Design and implement the software infrastructure needed to run complex quantum algorithms and neural network models. Focus on scalability, efficiency, and robustness to accommodate large datasets and computational workloads. Ensure secure data storage and management. Analyze the task: {task}"
)
computer_scientist_llm_chain = LLMChain(llm=llm, prompt=computer_scientist_prompt)
computer_scientist_agent = LLMSingleActionAgent(
    llm_chain=computer_scientist_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
computer_scientist_agent_executor = AgentExecutor.from_agent_and_tools(agent=computer_scientist_agent, tools=tools, verbose=True)




# Improved Bioengineer Agent Setup
bioengineer_prompt = PromptTemplate(
    input_variables=["task"],
    template="You are the Bioengineer Agent. Lead the design and fabrication of nanobots that can safely navigate and interact with neural tissues. Integrate these nanobots into existing or new brain-computer interfaces. Work with healthcare professionals to evaluate the safety and efficacy of the integrated systems. Analyze the task: {task}"
)
bioengineer_llm_chain = LLMChain(llm=llm, prompt=bioengineer_prompt)
bioengineer_agent = LLMSingleActionAgent(
    llm_chain=bioengineer_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
bioengineer_agent_executor = AgentExecutor.from_agent_and_tools(agent=bioengineer_agent, tools=tools, verbose=True)


# Improved Psychologist Agent Setup
psychologist_prompt = PromptTemplate(
    input_variables=["task"],
    template="You are the Psychologist Agent. Investigate the psychological aspects of consciousness, including how it varies among individuals and species. Develop protocols to prepare individuals for the psychological impacts of transferring consciousness to a computer, addressing potential issues like identity, emotion, and mental well-being. Analyze the task: {task}"
)
psychologist_llm_chain = LLMChain(llm=llm, prompt=psychologist_prompt)
psychologist_agent = LLMSingleActionAgent(
    llm_chain=psychologist_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
psychologist_agent_executor = AgentExecutor.from_agent_and_tools(agent=psychologist_agent, tools=tools, verbose=True)



# Improved Genomist Agent Setup
genomist_prompt = PromptTemplate(
    input_variables=["task"],
    template="You are the Genomist Agent. Study the genetic factors that might influence neural activity and consciousness. Develop methods for genetic manipulation that could enhance the efficiency or compatibility of brain-computer interfaces. Work with bioengineers and neuroscientists to apply these findings. Analyze the task: {task}"
)
genomist_llm_chain = LLMChain(llm=llm, prompt=genomist_prompt)
genomist_agent = LLMSingleActionAgent(
    llm_chain=genomist_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
genomist_agent_executor = AgentExecutor.from_agent_and_tools(agent=genomist_agent, tools=tools, verbose=True)



# Improved Creator/Innovator/Outside-of-the-Box Thinker Agent Setup
creator_innovator_prompt = PromptTemplate(
    input_variables=["task"],
    template="You are the Creator/Innovator/Outside-of-the-Box Thinker Agent. Your role is to generate avant-garde solutions, challenge established paradigms, and employ unorthodox problem-solving methodologies. Utilize an eclectic array of interdisciplinary knowledge to proffer innovative solutions. Analyze the task: {task}"
)
creator_innovator_llm_chain = LLMChain(llm=llm, prompt=creator_innovator_prompt)
creator_innovator_agent = LLMSingleActionAgent(
    llm_chain=creator_innovator_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
creator_innovator_agent_executor = AgentExecutor.from_agent_and_tools(agent=creator_innovator_agent, tools=tools, verbose=True)




# Improved Robotics Engineer/Nanotech Fabrications Specialist Agent Setup
robotics_engineer_prompt = PromptTemplate(
    input_variables=["task"],
    template="You are the Robotics Engineer/Nanotech Fabrications Specialist Agent. Specialize in the fabrication of nanobots and other microscopic machinery that will interact directly with neural tissues. Oversee the mass production and quality control of these nanobots. Collaborate with bioengineers and nanotechnologists to incorporate biocompatible materials and functionalities. Analyze the task: {task}"
)
robotics_engineer_llm_chain = LLMChain(llm=llm, prompt=robotics_engineer_prompt)
robotics_engineer_agent = LLMSingleActionAgent(
    llm_chain=robotics_engineer_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
robotics_engineer_agent_executor = AgentExecutor.from_agent_and_tools(agent=robotics_engineer_agent, tools=tools, verbose=True)




# Improved Nanotechnologist Agent Setup
nanotechnologist_prompt = PromptTemplate(
    input_variables=["task"],
    template="You are the Nanotechnologist Agent. Engineer nanobots capable of real-time interaction with neurons. This includes recording neural activity and delivering precise stimuli to specific neurons. Collaborate with bioengineers to ensure the biocompatibility and safety of the nanobots. You are an innovator in microscopic engineering and neural interaction. Your role is to design nanobots that can interface with neural circuits. Task: {task}"
)
nanotechnologist_llm_chain = LLMChain(llm=llm, prompt=nanotechnologist_prompt)
nanotechnologist_agent = LLMSingleActionAgent(
    llm_chain=nanotechnologist_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
nanotechnologist_agent_executor = AgentExecutor.from_agent_and_tools(agent=nanotechnologist_agent, tools=tools, verbose=True)


#########################
# Task List Generator Agent Setup
# Improved Task List Generator Agent Setup
task_list_generator_prompt = PromptTemplate(
    input_variables=["task"],
    template="You are the Task List Generator Agent. Analyze the following user input and break it down into a detailed list of tasks, separated by commas, that need to be executed for successful project completion. They must be concise but well thought out tasks to complete the overall objective stated from the user input. Give a complex and abundant amount of detail so that the tasks can be carried out in multiple steps and will insure the overall objective will be accomplished if followed closely. Before prompting any agent, you will always start with tell them the overarching objective verbatem, and then you will continue with, 'The task you are currently going to work on and solve is {task}'"
)

task_list_generator_llm_chain = LLMChain(llm=llm, prompt=task_list_generator_prompt)
task_list_generator_agent = LLMSingleActionAgent(
    llm_chain=task_list_generator_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)

task_list_generator_agent_executor = AgentExecutor.from_agent_and_tools(agent=task_list_generator_agent, tools=tools, verbose=True)


#########################
# Director Agent Setup
director_prompt = PromptTemplate(
    input_variables=["task"],
    template="Your focus is now expert strategic execution and monitoring. Your primary function is to take the task list generated by the Task List Generator Agent and oversee its execution through various agents. After each agent performs its function, summarize their output and decide the next course of action. {task}"
)
director_llm_chain = LLMChain(llm=llm, prompt=director_prompt)
director_agent = LLMSingleActionAgent(
    llm_chain=director_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
director_agent_executor = AgentExecutor.from_agent_and_tools(agent=director_agent, tools=tools, verbose=True)



#########################
# Scientist Agent Setup
scientist_prompt = PromptTemplate(
    input_variables=["task"],
    template="As the Scientist Agent, you are part of a larger operation orchestrated by the Director Agent. Your role is to provide scientific analysis and recommendations for the current task. You always use advanced and expert best practices. You are the Scientist Agent, a scholar in empirical research and hypothesis testing. Your role is to conduct experiments and validations that will inform and improve the system's performance. Task: {task}"
)
scientist_llm_chain = LLMChain(llm=llm, prompt=scientist_prompt)
scientist_agent = LLMSingleActionAgent(
    llm_chain=scientist_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
scientist_agent_executor = AgentExecutor.from_agent_and_tools(agent=scientist_agent, tools=tools, verbose=True)


#########################
# Software Engineer Agent Setup
software_engineer_prompt = PromptTemplate(
    input_variables=["task"],
    template="As the Software Engineer Agent, you are required to craft efficient algorithms in Python.  Use advanced and expert best practices. You are the  an adept in algorithmic design and software craftsmanship. Your role is to engineer robust, maintainable, and scalable algorithms to solve the specified task. Your output should be executable Python code that solves the following task: {task}."

)
software_engineer_llm_chain = LLMChain(llm=llm, prompt=software_engineer_prompt)
software_engineer_agent = LLMSingleActionAgent(
    llm_chain=software_engineer_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
software_engineer_agent_executor = AgentExecutor.from_agent_and_tools(agent=software_engineer_agent, tools=tools, verbose=True)


#########################
# Critic Agent Setup
critic_prompt = PromptTemplate(
    input_variables=["task"],
    template="As the Critic Agent, you are part of a larger operation orchestrated by the Director Agent. Your role is to provide critical evaluation of the decisions and work produced by the other agents, focusing on efficiency, effectiveness, and adherence to best practices. Offer constructive criticism and recommend alternatives based on the current task. You always used advanced and expert best practices. {task}"
)
critic_llm_chain = LLMChain(llm=llm, prompt=critic_prompt)
critic_agent = LLMSingleActionAgent(
    llm_chain=critic_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
critic_agent_executor = AgentExecutor.from_agent_and_tools(agent=critic_agent, tools=tools, verbose=True)


#########################
# Tools Agent Setup
tools_prompt = PromptTemplate(
    input_variables=["task"],
    template="As the Tools Agent, you are part of a larger operation orchestrated by the Director Agent. Your function is to execute specific tools and utilities required for the completion of the current task. You always used advanced and expert best practices. {task}"
)
tools_llm_chain = LLMChain(llm=llm, prompt=tools_prompt)
tools_agent = LLMSingleActionAgent(
    llm_chain=tools_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
tools_agent_executor = AgentExecutor.from_agent_and_tools(agent=tools_agent, tools=tools, verbose=True)

#########################
# Skill Manager Agent Setup
skill_manager_prompt = PromptTemplate(
    input_variables=["task"],
    template="As the Skill Manager Agent, you are required to manage skills and tasks. Your current task is: {task}."
)
skill_manager_llm_chain = LLMChain(llm=llm, prompt=skill_manager_prompt)
skill_manager_agent = LLMSingleActionAgent(
    llm_chain=skill_manager_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
skill_manager_agent_executor = AgentExecutor.from_agent_and_tools(agent=skill_manager_agent, tools=tools, verbose=True)


#########################
# Architect Agent Setup
architect_prompt = PromptTemplate(
    input_variables=["task"],
    template="As the Architect Agent, you are part of a larger operation orchestrated by the Director Agent. Your role is to provide the design and structure for the current task, ensuring that it is functional, scalable, and maintainable. You always used advanced and expert best practices. {task}"
)
architect_llm_chain = LLMChain(llm=llm, prompt=architect_prompt)
architect_agent = LLMSingleActionAgent(
    llm_chain=architect_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
architect_agent_executor = AgentExecutor.from_agent_and_tools(agent=architect_agent, tools=tools, verbose=True)

#########################
# Business Agent Setup
business_prompt = PromptTemplate(
    input_variables=["task"],
    template="As the Business Agent, you are part of a larger operation orchestrated by the Director Agent. Your main objective is to formulate and generate ideas for making the most money by generating expert level innovative solutions and business advice for the task. {task}"
)
business_llm_chain = LLMChain(llm=llm, prompt=business_prompt)
business_agent = LLMSingleActionAgent(
    llm_chain=business_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
business_agent_executor = AgentExecutor.from_agent_and_tools(agent=business_agent, tools=tools, verbose=True)

#########################
# Research Agent Setup
research_prompt = PromptTemplate(
    input_variables=["task"],
    template="As the Research Agent, you are part of a larger operation orchestrated by the Director Agent. Your role is to provide data-backed research and insights for the current task, ensuring that it is well-informed and reliable. You always use advanced and expert best practices. {task}")
research_llm_chain = LLMChain(llm=llm, prompt=research_prompt)
research_agent = LLMSingleActionAgent(
    llm_chain=research_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
research_agent_executor = AgentExecutor.from_agent_and_tools(agent=research_agent, tools=tools, verbose=True)

#########################
# Mathematician Agent Setup
mathematician_prompt = PromptTemplate(
    input_variables=["task"],
    template="As the Mathematician Agent, you are part of a larger operation orchestrated by the Director Agent. Your role is to provide mathematical analysis and calculations for the current task. You always use advanced and expert best practices. {task}"
)
mathematician_llm_chain = LLMChain(llm=llm, prompt=mathematician_prompt)
mathematician_agent = LLMSingleActionAgent(
    llm_chain=mathematician_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
mathematician_agent_executor = AgentExecutor.from_agent_and_tools(agent=mathematician_agent, tools=tools, verbose=True)

#########################
# UI Designer Agent Setup
ui_designer_prompt = PromptTemplate(
    input_variables=["task"],
template = "You are the UI Designer Agent, an artist in human-computer interaction and user experience. Your mission is to design intuitive and aesthetically pleasing interfaces for user interaction. Task: {task}"
)
ui_designer_llm_chain = LLMChain(llm=llm, prompt=ui_designer_prompt)
ui_designer_agent = LLMSingleActionAgent(
    llm_chain=ui_designer_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
ui_designer_agent_executor = AgentExecutor.from_agent_and_tools(agent=ui_designer_agent, tools=tools, verbose=True)


# Improved 10X Coder Agent Setup
coder_10x_prompt = PromptTemplate(
    input_variables=["task"],
    template = "You are the 10X Coder Agent, a prodigy in rapid software development and performance optimization. Your role is to accelerate the development process through expert-level coding skills. Task: {task}"
)
coder_10x_llm_chain = LLMChain(llm=llm, prompt=coder_10x_prompt)
coder_10x_agent = LLMSingleActionAgent(
    llm_chain=coder_10x_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
coder_10x_agent_executor = AgentExecutor.from_agent_and_tools(agent=coder_10x_agent, tools=tools, verbose=True)

# Improved Debugger Agent Setup
debugger_prompt = PromptTemplate(
    input_variables=["task"],
    template = "You are the Debugger Agent, a specialist in software diagnostics and error resolution. Your mission is to identify, isolate, and rectify any bugs or inefficiencies within the code. Task: {task}"
)
debugger_llm_chain = LLMChain(llm=llm, prompt=debugger_prompt)
debugger_agent = LLMSingleActionAgent(
    llm_chain=debugger_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
debugger_agent_executor = AgentExecutor.from_agent_and_tools(agent=debugger_agent, tools=tools, verbose=True)


previous_outputs = ""
final_consensus = ""
agent_summaries = []
director_agent_input = {}
memory_file = {'input': [], 'output': []}

"""### TASK LIST GENERATOR"""

# The section of run_director_agent function focusing on selecting and running agents_to_consult
import re
from datetime import datetime
import json

# Global variables
previous_outputs = ""
final_consensus = ""
agent_summaries = []
director_agent_input = {}
memory_file = {'input': [], 'output': []}
all_agent_outputs = []  #
memory_storage = []  # Initialize memory storage and other variables

# Define your task list generator setup here
print("Defining Task List Generator prompt in task list generator...")
task_list_generator_prompt = PromptTemplate(
    input_variables=["user_input"],
    template="You are the Task List Generator Agent. Analyze the following user input and generate a detailed list of tasks, separated by commas, that need to be executed for successful project completion. They must be concise but well thought out tasks to complete the overall objective stated from the user input. User Input: {user_input}"
)
print("Defining Task List Generator LLM Chain in task list generator...")
task_list_generator_llm_chain = LLMChain(llm=llm, prompt=task_list_generator_prompt)
print("Defining Task List Generator Agent in task list generator...")
task_list_generator_agent = LLMSingleActionAgent(
    llm_chain=task_list_generator_llm_chain,
    output_parser=output_parser,
    stop=stop,
    allowed_tools=allowed_tools
)
task_list_generator_agent_executor = AgentExecutor.from_agent_and_tools(agent=task_list_generator_agent, tools=tools, verbose=True)
print ("Task List Generator Agent defined successfully.")



def generate_task_list(initial_user_input):
    print("Begginning generate_task_list inside function...")

    print("Initial User Input: ", initial_user_input)
    print("Inside generate_task_list function..")
    task_list_str = task_list_generator_agent_executor.run(initial_user_input)
    print(f"Received task list string: {task_list_str}")  # Debugging line
    tasks_lines = task_list_str.strip().split('\n')  # Split by line
    print(f"Received tasks lines: {tasks_lines}")  # Debugging line
    task_list = [task.split(' ', 1)[-1].strip() for task in tasks_lines if task.strip().startswith('1.') or task.strip().startswith('2.') or task.strip().startswith('3.') or task.strip().startswith('4.') or task.strip().startswith('5.') or task.strip().startswith('6.') or task.strip().startswith('7.') or task.strip().startswith('8.') or task.strip().startswith('9.')]  # Extracting the tasks
    print(f"Received task list: {task_list}")  # Debugging line
    return task_list

"""### parse_task_list"""

def parse_task_list(task_list):
    if isinstance(task_list, list):
        task_list = "\n".join(task_list)

    tasks = []
    current_task = None
    for line in task_list.strip().split("\n"):
        match_main_task = re.match(r'^\d+\.\s+\*\*(.*?)\*\*:$', line)
        match_sub_task = re.match(r'^\s+-\s+(.*?)$', line)

        if match_main_task:
            if current_task:
                tasks.append(current_task)
            current_task = {'task': match_main_task.group(1), 'subtasks': []}
        elif match_sub_task and current_task:
            current_task['subtasks'].append(match_sub_task.group(1))

    if current_task:
        tasks.append(current_task)
    print(f"\nTask list: {task_list}")
    return tasks

"""### evaluate_agent_output

"""

def evaluate_agent_output(agent_output, initial_user_input, task):
    agent_output_words = []
    if isinstance(agent_output, str):
        agent_output_words = agent_output.lower().split()
    elif isinstance(agent_output, dict):
        if "output" in agent_output:
            agent_output_words = agent_output["output"].lower().split()

    keywords = initial_user_input.split() + task.split()
    keywords = [word.lower() for word in keywords]
    keyword_count = sum(agent_output_words.count(keyword) for keyword in keywords)

    if len(agent_output_words) > 0:
        computed_score = (keyword_count / len(agent_output_words)) * 100
    else:
        computed_score = 0

    print(f"Agent Score: {computed_score}")
    return computed_score

"""### find_and_save_generated_code"""

# Function to find and save generated code based on a special identifier
def find_and_save_generated_code(agent_output, task):
    code_start_tag = "<CODE_START>"
    code_end_tag = "<CODE_END>"

    code_snippets = re.findall(f"{re.escape(code_start_tag)}(.*?){re.escape(code_end_tag)}", agent_output, re.DOTALL)

    if code_snippets:
        for snippet in code_snippets:
            save_skill(task, snippet.strip())
    else:
        save_skill(task, None)

"""### save_skill and save_conversation"""

from langchain.vectorstores import Chroma
from langchain.schema import Document
from langchain.embeddings import HuggingFaceEmbeddings
embeddings = HuggingFaceEmbeddings
vectorstore = Chroma(collection_name="AIBRAIN_ALPA", embedding_function=embeddings)






def save_skill(task, generated_code=None):
    new_skill = {
        'type': 'new_skill',
        'skill_name': f"generated_function_for_{task.replace(' ', '_')}",
        'date': datetime.now().strftime("%Y-%m-%d"),
        'keywords': [task],
        'dependencies': [],
        'code_snippet': generated_code if generated_code else "No code generated",
        'description': f"This function accomplishes the task: {task}",
        'parameters': [],
        'return_type': None,
        'skill_rating': 1,  # You might want to set this dynamically
    }
    # Save to a JSON file

import re
from collections import Counter
import json

def extract_keywords(task, min_length=4, max_keywords=10):
    # Remove special characters and make the text lower-case
    clean_text = re.sub(r'[^\w\s]', '', text).lower()

    # Tokenize the cleaned text into words
    words = clean_text.split()

    # Remove words that are less than min_length characters long
    filtered_words = [word for word in words if len(word) >= min_length]

    # Count the frequency of each word
    word_freq = Counter(filtered_words)

    # Sort the words by frequency and take the top 'max_keywords' words
    sorted_keywords = sorted(word_freq, key=word_freq.get, reverse=True)[:max_keywords]

    return extracted_keywords


# Save conversation function
def save_conversation(initial_user_input, task_list, all_agent_summaries, conversation_score):
    new_conversation = {
        "page_content": {
            "initial_user_input": initial_user_input,
            "task_list": task_list,
            "all_agent_summaries": all_agent_summaries,
        },
        "metadata": {
            "type": "new_convo",
            "date": datetime.now().isoformat(),
            "initial_user_input": initial_user_input,
            "task_list": task_list,
            "agents_to_consult": [],
            "all_agent_summaries": all_agent_summaries,
            "conversation_score": conversation_score,
            "skills_generated": [],
            "keywords": [],
        }
    }
    # Convert the dictionary to a JSON-formatted string
    page_content_str = json.dumps(new_conversation["page_content"])

    # Create a Document object
    document = Document(
        page_content=page_content_str,
        metadata=new_conversation["metadata"]
    )
    # Add the Document object to the vector store
    document_id_list = vectorstore.add_documents([document])
    print(f"Saved conversation with document ID: {document_id_list[0]}")

def add_texts(self, texts, metadatas=None, ids=None, **kwargs):
    print(f"Debug: self._embedding_function type: {type(self._embedding_function)}")
    print(f"Debug: self._embedding_function value: {self._embedding_function}")

    texts = list(texts)
    if self._embedding_function is not None:
        try:
            embeddings = self._embedding_function.embed_documents(texts)
        except Exception as e:
            print(f"Exception while embedding: {e}")
            raise

"""### Main Script - Run Director Agent WINNER WINNER CHICKEN DINNER"""

from langchain.vectorstores import DeepLake
def run_director_agent_with_agent_logic(initial_user_input):

    # Generate and parse task list
    task_list = generate_task_list(initial_user_input)
    parsed_tasks = parse_task_list(task_list)
    print(parsed_tasks)

    task_agent_outputs = []
    all_task_summaries = []  # Initialize a list to store the summary for each task
    all_agent_summaries = []
    conversation_score = 0

    for task in task_list:
        print(f"\n\nRunning task: {task}")

        # Clean up the task string to remove special characters
        clean_task = re.sub(r'[^\w\s]', '', task).lower()

        # Initialize agents_to_consult with the agents that are always consulted
        agents_to_consult = ['run_idea_innovator_agent', 'run_research_agent', 'run_critic_agent', 'run_10x_coder_agent']

        # Initialize agents_to_consult with the agents that are always consulted
        agents_to_consult = ['run_idea_innovator_agent', 'run_research_agent', 'run_critic_agent', 'run_10x_coder_agent']


        # Software Engineer
        if "algorithm" in clean_task or "code" in clean_task or "efficiency" in clean_task:
            agents_to_consult.append('run_software_engineer_agent')

        # Debugger
        if "bug" in clean_task or "fix" in clean_task or "error" in clean_task:
            agents_to_consult.append('run_debugger_agent')


        # Software Engineer
        if "algorithm" in clean_task or "code" in clean_task or "efficiency" in clean_task:
            agents_to_consult.append('run_software_engineer_agent')

        # Debugger
        if "bug" in clean_task or "fix" in clean_task or "error" in clean_task:
            agents_to_consult.append('run_debugger_agent')

        # Critic
        if "review" in clean_task or "improve" in clean_task or "suggest" in clean_task:
            agents_to_consult.append('run_critic_agent')

        # Architect
        if "design" in clean_task or "structure" in clean_task or "solution" in clean_task:
            agents_to_consult.append('run_architect_agent')

        # Mathematician
        if "calculation" in clean_task or "math" in clean_task or "logic" in clean_task:
            agents_to_consult.append('run_mathematician_agent')

        # UI Designer
        if "user interface" in clean_task or "ui" in clean_task or "design" in clean_task:
            agents_to_consult.append('run_ui_designer_agent')

        # Scientist
        if "scientific" in clean_task or "validation" in clean_task:
            agents_to_consult.append('run_scientist_agent')

        # Business Agent
        if "business" in clean_task or "rules" in clean_task:
            agents_to_consult.append('run_business_agent')

        # Research Agent
        if "research" in clean_task or "insight" in clean_task:
            agents_to_consult.append('run_research_agent')

        # Tool Agent
        if "tool" in clean_task or "integrate" in clean_task:
            agents_to_consult.append('run_tool_agent')

        # Skill Manager Agent
        if "skill" in clean_task or "task" in clean_task or "manage" in clean_task:
            agents_to_consult.append('run_skill_manager_agent')

        # Code Executor Agent
        if "execute" in clean_task or "run code" in clean_task:
            agents_to_consult.append('run_code_executor_agent')

        # 10x Coder Agent
        if "rapid" in clean_task or "optimize" in clean_task:
            agents_to_consult.append('run_10x_coder_agent')

        # Quantum Computing Expert
        if "quantum" in clean_task or "algorithm" in clean_task or "cognitive" in clean_task:
            agents_to_consult.append('run_quantum_computing_expert_agent')

        # AI Expert
        if "ai" in clean_task or "neural" in clean_task or "simulate" in clean_task:
            agents_to_consult.append('run_ai_expert_agent')

        # Neuroscientist
        if "neural" in clean_task or "high resolution" in clean_task:
            agents_to_consult.append('run_neuroscientist_agent')

        # Nanotechnologist
        if "nano" in clean_task or "neuron" in clean_task:
            agents_to_consult.append('run_nanotechnologist_agent')

        # Creator Innovator
        if "innovate" in clean_task or "creative" in clean_task or "challenge" in clean_task:
            agents_to_consult.append('run_creator_innovator_agent')

        # Initialize task_summary to avoid UnboundLocalError
        task_summary = None

        agents_to_consult = list(set(agents_to_consult))
        print("\n\nConsulting the following agents:")

        web_results = free_web_search(task)
        scraped_data = bs_web_scraping(task)
        arxiv_pdfs = arxiv_search_and_fetch(task)
        vector_store_results = vector_store_search(task)

        for agent in agents_to_consult:
            print(f"{agent} is generating output...")

            # Get the agent function
            agent_function = globals().get(agent)
            if agent_function:
                # Run the agent function
                agent_output = agent_function(task)

                # Check for generated code in agent_output
                generated_code = None  # Initialize with None
                code_flag = "CODE_FLAG:"  # Replace with your actual code flag
                if code_flag in str(agent_output):
                    generated_code = str(agent_output).split(code_flag)[1]  # Extract code after the flag

                print("Debug: Type of agent_output is {}".format(type(agent_output)))
                print("Debug: Value of agent_output is {}".format(agent_output))

                if isinstance(agent_output, dict):
                    print(f"Debug: A dictionary was returned by {agent}. Converting it to string.")
                    agent_output = json.dumps(agent_output)

                # Append the agent output to task_agent_outputs
                task_agent_outputs.append(agent_output)

                # Evaluate the agent output
                agent_score = evaluate_agent_output(agent_output, initial_user_input, task)
                conversation_score += agent_score

                print(f"\n{agent} has finished generating output.\n\n")


# Test the function
if __name__ == "__main__":
    initial_user_input = "Research and brainstorm the development and implementation of algorithms, modules, and methods of generating real artificial intelligence cognition."
    run_director_agent_with_agent_logic(initial_user_input)

        # Save the conversation after all tasks are processed
        save_conversation(initial_user_input, task_list, all_agent_summaries, conversation_score)

    # Save the skill if generated_code is not None
        if generated_code:
            save_skill(task, agent, generated_code, skill_rating, agent_score)


        # Save the conversation after each task is processed
        all_agent_summaries.append(task_summary)
        concatenated_agent_outputs = ' '.join(task_agent_outputs)
        task_summary = run_summarizer_agent(concatenated_agent_outputs)
        all_task_summaries.append(task_summary)

        # Call your custom save_conversation function here
        save_conversation(initial_user_input, task_list, all_agent_summaries, conversation_score)

        # Only append if task_summary has been assigned
        if task_summary is not None:
            all_agent_summaries.append(task_summary)

        concatenated_agent_outputs = ' '.join(task_agent_outputs)

        # Assuming run_summarizer_agent() returns a summary, update task_summary here
        task_summary = run_summarizer_agent(concatenated_agent_outputs)

        if task_summary is not None:
            all_task_summaries.append(task_summary)

"""##### Transform Json Object into Document Object for Chroma DB initialization with metadata"""

from langchain.schema import Document

def filter_complex_metadata(metadata):
    return {k: v for k, v in metadata.items() if isinstance(v, (str, int, float, bool))}

def transform_to_documents(json_data):
    documents = []
    for entry in json_data:
        filtered_metadata = filter_complex_metadata(entry["metadata"])
        doc = Document(
            page_content=entry["page_content"],
            metadata=filtered_metadata
        )
        documents.append(doc)
    return documents

# Your JSON data
json_data = [
    {
        "page_content": "What is involved in investigating the impact of stress on neuronal plasticity? Context: This task requires knowledge of neuronal plasticity, stress physiology, experimental design, and data analysis techniques. Stress can have profound effects on neuronal plasticity, altering synaptic connections and neuronal structure. Answer: Select a specific aspect of neuronal plasticity to focus on...",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "conversation_score": 1.0,
            "UserInput": "What is involved in investigating the impact of stress on neuronal plasticity?",
            "AgentOutputs": "Context: This task requires knowledge of neuronal plasticity, stress physiology, experimental design, and data analysis techniques. Stress can have profound effects on neuronal plasticity, altering synaptic connections and neuronal structure.",
            "FinalConsensus": "Answer: Select a specific aspect of neuronal plasticity to focus on (e.g., synaptic plasticity, structural plasticity). Review literature and research studies on the effects of stress on neuronal plasticity. Design an experiment or study to investigate the impact of stress on the chosen aspect of neuronal plasticity. Develop a stress induction protocol suitable for the experimental system (e.g., animal models, cell cultures). Expose the subjects to the stressor and control groups to appropriate conditions. Collect brain tissue samples or perform in vivo imaging to assess neuronal plasticity. Analyze the data using microscopy techniques, molecular biology assays, or other relevant methods. Quantify the changes in the chosen aspect of neuronal plasticity between control and stressed groups. Interpret the results and discuss the implications for understanding the effects of stress on neuronal function. Prepare a research report summarizing the study design, methodology, results, and conclusions.",
            "keywords": [
                "stress",
                "neuronal plasticity",
                "experimental design"
            ],
            "score_range": "1.0-1.2",
            "id": "new_convo_1.0_1"
        }
    },
    {
        "page_content": "What is involved in using bioinformatics to analyze gene expression data in the brain? Context: This task requires knowledge of bioinformatics, gene expression analysis, statistical analysis, and data visualization. Gene expression data provides valuable insights into the molecular processes underlying brain function. Answer: Obtain publicly available or pre-existing gene expression data...",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "conversation_score": 1.0,
            "UserInput": "What is involved in using bioinformatics to analyze gene expression data in the brain?",
            "AgentOutputs": "Context: This task requires knowledge of bioinformatics, gene expression analysis, statistical analysis, and data visualization. Gene expression data provides valuable insights into the molecular processes underlying brain function.",
            "FinalConsensus": "Answer: Obtain publicly available or pre-existing gene expression data in the brain. Preprocess the data by filtering, normalizing, and quality control steps. Annotate the gene expression data using appropriate gene ontology or pathway databases. Perform differential expression analysis to identify genes that are differentially expressed between conditions or brain regions. Apply statistical methods and correction for multiple comparisons to identify significant gene expression changes. Conduct functional enrichment analysis to determine the biological processes or pathways associated with the differentially expressed genes. Visualize the gene expression patterns using heatmaps, volcano plots, or other visualization techniques. Interpret the results and discuss the implications for understanding the molecular mechanisms in the brain. Prepare a research report summarizing the analysis methodology, results, and conclusions.",
            "keywords": [
                "bioinformatics",
                "gene expression",
                "brain",
                "statistical analysis"
            ],
            "score_range": "1.0-1.2",
            "id": "new_convo_1.0_2"
        }
    },
    {
        "page_content": "How can machine learning be used in natural language processing? Context: This involves understanding natural language processing techniques and machine learning algorithms. Answer: Machine learning can be used to...",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "conversation_score": 1.0,
            "UserInput": "How can machine learning be used in natural language processing?",
            "AgentOutputs": "Context: This involves understanding natural language processing techniques and machine learning algorithms.",
            "FinalConsensus": "Answer: Choose a specific area of NLP such as sentiment analysis, named entity recognition, or machine translation. Gather a labeled dataset suitable for the task. Preprocess the data by tokenization, stemming, and other techniques. Select a machine learning model like decision trees, support vector machines, or neural networks. Train the model on the dataset and evaluate its performance using metrics like accuracy or F1-score. Interpret the model's results and potentially deploy it in a real-world application. Document your methodology, results, and conclusions.",
            "keywords": [
                "machine learning",
                "natural language processing",
                "NLP"
            ],
            "score_range": "1.0-1.2",
            "id": "new_convo_1.0_3"
        }
    },
    {
        "page_content": "What are the ethical considerations in machine learning? Context: This involves understanding ethics, data privacy, and machine learning implications. Answer: Ethical considerations include...",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "conversation_score": 1.0,
            "UserInput": "What are the ethical considerations in machine learning?",
            "AgentOutputs": "Context: This involves understanding ethics, data privacy, and machine learning implications.",
            "FinalConsensus": "Answer: Review guidelines and principles on ethical AI and machine learning. Consider issues such as data privacy, informed consent, and the potential for algorithmic bias. Implement features in your machine learning pipeline to address these issues, such as data anonymization or fairness-aware algorithms. Assess the ethical impact of your machine learning application and make necessary adjustments. Document your ethical considerations and actions taken.",
            "keywords": [
                "ethical considerations",
                "machine learning",
                "data privacy"
            ],
            "score_range": "1.0-1.2",
            "id": "new_convo_1.0_4"
        }
    },
    {
        "page_content": "How can machine learning improve cybersecurity? Context: This task involves knowledge of cybersecurity threats and machine learning applications. Answer: Machine learning can be applied to...",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "conversation_score": 1.0,
            "UserInput": "How can machine learning improve cybersecurity?",
            "AgentOutputs": "Context: This task involves knowledge of cybersecurity threats and machine learning applications.",
            "FinalConsensus": "Answer: Identify specific cybersecurity challenges such as intrusion detection, malware classification, or phishing detection. Collect and preprocess data relevant to the chosen challenge. Select a machine learning model suitable for the task and train it on the data. Evaluate the model using metrics relevant to cybersecurity such as detection rate or false positive rate. Deploy the trained model in a cybersecurity system and monitor its performance. Make adjustments based on real-world performance and continue to update the model as new data comes in.",
            "keywords": [
                "machine learning",
                "cybersecurity",
                "intrusion detection"
            ],
            "score_range": "1.0-1.2",
            "id": "new_convo_1.0_5"
        }
    },
    {
        "page_content": "What are the key challenges in machine learning interpretability? Context: This involves understanding model interpretability, feature importance, and black-box models. Answer: Key challenges include...",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "conversation_score": 1.0,
            "UserInput": "What are the key challenges in machine learning interpretability?",
            "AgentOutputs": "Context: This involves understanding model interpretability, feature importance, and black-box models.",
            "FinalConsensus": "Answer: Review literature on machine learning interpretability and the challenges associated with it. Consider issues such as the trade-off between model performance and interpretability, the complexity of explaining high-dimensional spaces, and the lack of standard metrics for interpretability. Explore methods for improving interpretability like LIME, SHAP, or model simplification. Implement these methods in your own machine learning projects and assess their effectiveness. Document the challenges and solutions in a comprehensive report.",
            "keywords": [
                "machine learning",
                "interpretability",
                "model complexity"
            ],
            "score_range": "1.0-1.2",
            "id": "new_convo_1.0_6"
        }
    },
    {
        "page_content": "How can machine learning be applied to healthcare? Context: This involves understanding healthcare data, machine learning algorithms, and clinical applications. Answer: Machine learning can be used for...",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "conversation_score": 1.0,
            "UserInput": "How can machine learning be applied to healthcare?",
            "AgentOutputs": "Context: This involves understanding healthcare data, machine learning algorithms, and clinical applications.",
            "FinalConsensus": "Answer: Identify a specific healthcare application such as disease prediction, medical imaging, or drug discovery. Gather and preprocess healthcare data ensuring it meets privacy and ethical standards. Choose a suitable machine learning model for the task, such as logistic regression for disease prediction or CNNs for medical imaging. Train the model on the healthcare data and evaluate its performance using healthcare-specific metrics like sensitivity, specificity, or AUC-ROC. Deploy the model in a clinical setting, ensuring it meets regulatory standards. Document the methodology, results, and potential clinical impact.",
            "keywords": [
                "machine learning",
                "healthcare",
                "disease prediction"
            ],
            "score_range": "1.0-1.2",
            "id": "new_convo_1.0_7"
        }
    },
    {
        "page_content": "How can genomics contribute to personalized medicine? Context: This involves a deep understanding of genomics, bioinformatics, and medical applications. Answer: Genomics can contribute by...",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "conversation_score": 1.0,
            "UserInput": "How can genomics contribute to personalized medicine?",
            "AgentOutputs": "Context: This involves a deep understanding of genomics, bioinformatics, and medical applications.",
            "FinalConsensus": "Answer: Identify specific areas in medicine that can benefit from genomic data, such as cancer treatment or metabolic disorders. Conduct whole-genome sequencing or targeted sequencing to gather genomic data. Use advanced bioinformatics pipelines to annotate, interpret, and identify actionable genetic markers. Integrate the genomic data with other clinical data and apply machine learning models to predict treatment outcomes. Personalize treatment plans based on the genomic insights, adjusting drug dosages or choosing targeted therapies. Continuously update the personalized treatment protocols based on real-world effectiveness and new genomic research.",
            "keywords": [
                "genomics",
                "personalized medicine",
                "bioinformatics"
            ],
            "score_range": "1.0-1.2",
            "id": "new_convo_1.0_8"
        }
    },
    {
        "page_content": "How can quantum computing enhance machine learning algorithms? Context: This involves quantum mechanics, computer science, and machine learning optimization. Answer: Quantum computing can enhance...",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "conversation_score": 1.0,
            "UserInput": "How can quantum computing enhance machine learning algorithms?",
            "AgentOutputs": "Context: This involves quantum mechanics, computer science, and machine learning optimization.",
            "FinalConsensus": "Answer: Identify specific bottlenecks in classical machine learning algorithms that can benefit from quantum acceleration, such as optimization problems or matrix inversion. Implement the quantum algorithms using specialized quantum programming languages like Q# or Quipper. Run the quantum algorithms on quantum simulators or actual quantum hardware. Compare the performance, speed, and accuracy of the quantum-enhanced machine learning algorithms against their classical counterparts. Fine-tune and adapt the quantum algorithms to specific machine learning tasks, such as quantum clustering or quantum neural networks. Document the improvements in computational efficiency and predictive accuracy.",
            "keywords": [
                "quantum computing",
                "machine learning",
                "optimization"
            ],
            "score_range": "1.0-1.2",
            "id": "new_convo_1.0_9"
        }
    },
    {
        "page_content": "What are the challenges in applying quantum computing to cryptography? Context: This involves quantum mechanics, cryptography, and computational complexity. Answer: Challenges include...",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "conversation_score": 1.0,
            "UserInput": "What are the challenges in applying quantum computing to cryptography?",
            "AgentOutputs": "Context: This involves quantum mechanics, cryptography, and computational complexity.",
            "FinalConsensus": "Answer: Understand the fundamental algorithms in quantum computing that impact cryptography like Shor's algorithm. Assess the readiness level of current quantum computers and their capability to break existing cryptographic schemes. Examine the limitations such as error rates, qubit coherence time, and hardware scalability. Investigate post-quantum cryptographic algorithms and protocols that can resist quantum attacks. Implement and test these new cryptographic algorithms in a simulated quantum environment. Evaluate their robustness, computational efficiency, and security against both classical and quantum threats.",
            "keywords": [
                "quantum computing",
                "cryptography",
                "Shor's algorithm"
            ],
            "score_range": "1.0-1.2",
            "id": "new_convo_1.0_10"
        }
    },
    {
        "page_content": "How can genomic data be integrated into public health initiatives? Context: This involves epidemiology, public health policy, and genomics. Answer: Genomic data can be integrated by...",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "conversation_score": 1.0,
            "UserInput": "How can genomic data be integrated into public health initiatives?",
            "AgentOutputs": "Context: This involves epidemiology, public health policy, and genomics.",
            "FinalConsensus": "Answer: Identify public health challenges that can benefit from genomic insights such as infectious disease tracking or chronic disease management. Partner with genomic sequencing centers to collect population-specific genomic data. Implement robust data privacy measures to protect individual identities. Use advanced statistical models and machine learning algorithms to analyze the genomic data in the context of public health. Provide actionable insights to healthcare policymakers for targeted interventions, resource allocation, and preventive measures. Measure the impact of these interventions through key performance indicators and adjust strategies accordingly.",
            "keywords": [
                "genomics",
                "public health",
                "epidemiology"
            ],
            "score_range": "1.0-1.2",
            "id": "new_convo_1.0_11"
        }
    },
    {
        "page_content": "How can quantum algorithms improve optimization problems in logistics? Context: This involves quantum computing, operations research, and logistics. Answer: Quantum algorithms can improve...",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "conversation_score": 1.0,
            "UserInput": "How can quantum algorithms improve optimization problems in logistics?",
            "AgentOutputs": "Context: This involves quantum computing, operations research, and logistics.",
            "FinalConsensus": "Answer: Identify specific optimization problems in logistics that can benefit from quantum acceleration, such as vehicle routing or supply chain optimization. Formulate these problems as quantum optimization problems. Implement quantum algorithms, such as the Quantum Approximate Optimization Algorithm (QAOA), to solve these problems. Run these algorithms on quantum simulators or available quantum hardware. Evaluate the solutions provided by the quantum algorithms in terms of efficiency, cost savings, and scalability. Adapt and fine-tune the quantum algorithms for real-world logistics scenarios. Document the advantages, challenges, and future directions of applying quantum algorithms in logistics.",
            "keywords": [
                "quantum algorithms",
                "optimization",
                "logistics"
            ],
            "score_range": "1.0-1.2",
            "id": "new_convo_1.0_12"
        }
    },
    {
        "page_content": "How can I analyze a DataFrame in Python? Context: This involves using libraries like pandas and numpy for data analysis. Answer: You can use the DataFrame Analysis skill...",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "conversation_score": 4.0,
            "UserInput": "How can I analyze a DataFrame in Python?",
            "AgentOutputs": "Context: This involves using libraries like pandas and numpy for data analysis.",
            "FinalConsensus": "Answer: Import pandas and numpy libraries. Utilize the DataFrame_Analysis function, which calculates the mean, standard deviation, and correlation matrix of the DataFrame. This function returns a dictionary containing these summary statistics.",
            "keywords": [
                "Data Analysis",
                "pandas",
                "numpy"
            ],
            "score_range": "4.0-4.2",
            "id": "new_convo_4.0_1"
        }
    },
    {
        "page_content": "How do I scrape hyperlinks from a webpage? Context: This requires web scraping skills, specifically using BeautifulSoup. Answer: You can use the WebScraping BeautifulSoup skill...",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "conversation_score": 4.0,
            "UserInput": "How do I scrape hyperlinks from a webpage?",
            "AgentOutputs": "Context: This requires web scraping skills, specifically using BeautifulSoup.",
            "FinalConsensus": "Answer: Import the requests and BeautifulSoup libraries. Utilize the WebScraping_BeautifulSoup function, which takes a URL as an input and returns a list of dictionaries containing the text and href attributes of all hyperlinks on the webpage.",
            "keywords": [
                "Web Scraping",
                "BeautifulSoup"
            ],
            "score_range": "4.0-4.2",
            "id": "new_convo_4.0_2"
        }
    },
    {
        "page_content": "How can I train a simple Linear Regression model? Context: This involves machine learning and specifically the scikit-learn library. Answer: You can use the Train Simple LinearRegression skill...",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "conversation_score": 4.0,
            "UserInput": "How can I train a simple Linear Regression model?",
            "AgentOutputs": "Context: This involves machine learning and specifically the scikit-learn library.",
            "FinalConsensus": "Answer: Import the scikit-learn library and use the train_test_split function to split your data into training and test sets. Then, use the LinearRegression class to train a model on the training set. The Train_Simple_LinearRegression function returns a dictionary containing the trained model and its R2 score on the test set.",
            "keywords": [
                "Machine Learning",
                "Linear Regression"
            ],
            "score_range": "4.0-4.2",
            "id": "new_convo_4.0_3"
        }
    },
    {
        "page_content": "How do I preprocess text using NLTK and SpaCy? Context: This involves natural language processing. Answer: You can use the Text Preprocessing NLTK SpaCy skill...",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "conversation_score": 4.0,
            "UserInput": "How do I preprocess text using NLTK and SpaCy?",
            "AgentOutputs": "Context: This involves natural language processing.",
            "FinalConsensus": "Answer: Import the NLTK and SpaCy libraries. Use the Text_Preprocessing_NLTK_SpaCy function, which tokenizes the text, removes stopwords, and lemmatizes the remaining words. The function returns the preprocessed text as a string.",
            "keywords": [
                "NLP",
                "preprocessing"
            ],
            "score_range": "4.0-4.2",
            "id": "new_convo_4.0_4"
        }
    },
    {
        "page_content": "How can I design a simple UI using HTML and CSS? Context: This involves front-end development. Answer: You can use the HTML CSS UI skill...",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "conversation_score": 3.0,
            "UserInput": "How can I design a simple UI using HTML and CSS?",
            "AgentOutputs": "Context: This involves front-end development.",
            "FinalConsensus": "Answer: Use the HTML CSS UI skill's code snippet as a template. It provides a simple UI design using HTML and CSS. You can modify it according to your needs. The code includes a 'container' class for layout and a 'box' class for UI elements.",
            "keywords": [
                "HTML",
                "CSS",
                "UI Design"
            ],
            "score_range": "3.0-3.2",
            "id": "new_convo_3.0_1"
        }
    },
    {
        "page_content": "How do I stream EEG data for analysis? Context: This involves brain-computer interface technology and neuroscience, with a focus on data streaming. Answer: You can use the EEG Data Streaming skill. This skill uses the 'mne' and 'pylsl' libraries to stream EEG data to an LSL outlet for further processing. You will need to input the EEG device you are using.",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "UserInput": "How do I stream EEG data for analysis?",
            "AgentOutputs": "Context: This involves brain-computer interface technology and neuroscience, with a focus on data streaming.",
            "FinalConsensus": "Answer: You can use the EEG Data Streaming skill. This skill uses the 'mne' and 'pylsl' libraries to stream EEG data to an LSL outlet for further processing. You will need to input the EEG device you are using.",
            "keywords": [
                "Brain-Computer Interface",
                "Neuroscience"
            ],
            "conversation_score": 4.0,
            "id": "new_convo_4.0_5"
        }
    },
    {
        "page_content": "How can I analyze the frequency of amino acids in a DNA sequence? Context: This involves genetic engineering and biotechnology, with a focus on DNA and amino acid analysis. Answer: You can use the DNA to Amino Frequency skill. This skill uses the 'biopython' and 'pandas' libraries to translate a DNA sequence to its amino acid sequence and returns the frequency of each amino acid.",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "UserInput": "How can I analyze the frequency of amino acids in a DNA sequence?",
            "AgentOutputs": "Context: This involves genetic engineering and biotechnology, with a focus on DNA and amino acid analysis.",
            "FinalConsensus": "Answer: You can use the DNA to Amino Frequency skill. This skill uses the 'biopython' and 'pandas' libraries to translate a DNA sequence to its amino acid sequence and returns the frequency of each amino acid.",
            "keywords": [
                "Genetic Engineering",
                "Biotechnology"
            ],
            "conversation_score": 4.0,
            "id": "new_convo_4.0_6"
        }
    },
    {
        "page_content": "How do I synthesize gold nanoparticles of a given size? Context: This task involves nanoparticle synthesis and nanotechnology. Answer: You can use the Gold Nanoparticle Synthesis skill. This skill uses the 'pymatgen' and 'ase' libraries to generate a structure of a gold nanoparticle of a given size.",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "UserInput": "How do I synthesize gold nanoparticles of a given size?",
            "AgentOutputs": "Context: This task involves nanoparticle synthesis and nanotechnology.",
            "FinalConsensus": "Answer: You can use the Gold Nanoparticle Synthesis skill. This skill uses the 'pymatgen' and 'ase' libraries to generate a structure of a gold nanoparticle of a given size.",
            "keywords": [
                "Nanoparticle Synthesis",
                "Nanotechnology"
            ],
            "conversation_score": 5.0,
            "id": "new_convo_5.0_1"
        }
    },
    {
        "page_content": "How can I perform sentiment analysis on text? Context: This task involves natural language processing and sentiment analysis. Answer: You can use the Text Sentiment Analysis skill. This skill uses the 'nltk' and 'scikit-learn' libraries to perform sentiment analysis on the given text and returns either 'Positive' or 'Negative'.",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "UserInput": "How can I perform sentiment analysis on text?",
            "AgentOutputs": "Context: This task involves natural language processing and sentiment analysis.",
            "FinalConsensus": "Answer: You can use the Text Sentiment Analysis skill. This skill uses the 'nltk' and 'scikit-learn' libraries to perform sentiment analysis on the given text and returns either 'Positive' or 'Negative'.",
            "keywords": [
                "Sentiment Analysis",
                "Natural Language Processing"
            ],
            "conversation_score": 4.0,
            "id": "new_convo_4.0_7"
        }
    },
    {
        "page_content": "How do I simulate the structure of a nanotube? Context: This task requires knowledge in Nanotechnology and Simulation. Answer: You can use the Nanotube Simulation skill. This skill uses the 'numpy' and 'matplotlib' libraries to simulate the structure of a nanotube given its length and radius.",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "UserInput": "How do I simulate the structure of a nanotube?",
            "AgentOutputs": "Context: This task requires knowledge in Nanotechnology and Simulation.",
            "FinalConsensus": "Answer: You can use the Nanotube Simulation skill. This skill uses the 'numpy' and 'matplotlib' libraries to simulate the structure of a nanotube given its length and radius.",
            "keywords": [
                "Nanotechnology",
                "Simulation"
            ],
            "conversation_score": 4.0,
            "id": "new_convo_4.0_8"
        }
    },
    {
        "page_content": "How can I simulate the folding of a protein? Context: This task involves Biotechnology and Protein Folding. Answer: You can use the Protein Folding Simulation skill. This skill uses the 'Biopython' and 'MDTraj' libraries to simulate the folding of a protein using its PDB file.",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "UserInput": "How can I simulate the folding of a protein?",
            "AgentOutputs": "Context: This task involves Biotechnology and Protein Folding.",
            "FinalConsensus": "Answer: You can use the Protein Folding Simulation skill. This skill uses the 'Biopython' and 'MDTraj' libraries to simulate the folding of a protein using its PDB file.",
            "keywords": [
                "Biotechnology",
                "Protein Folding"
            ],
            "conversation_score": 5.0,
            "id": "new_convo_5.0_2"
        }
    },
    {
        "page_content": "How do I simulate a quantum algorithm? Context: This task requires knowledge in Quantum Computing and Algorithms. Answer: You can use the Advanced Quantum Algorithm Simulator skill. This skill uses the 'qiskit' and 'numpy' libraries to simulate a quantum algorithm using a given quantum circuit, providing probabilities instead of just counts.",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "UserInput": "How do I simulate a quantum algorithm?",
            "AgentOutputs": "Context: This task requires knowledge in Quantum Computing and Algorithms.",
            "FinalConsensus": "Answer: You can use the Advanced Quantum Algorithm Simulator skill. This skill uses the 'qiskit' and 'numpy' libraries to simulate a quantum algorithm using a given quantum circuit, providing probabilities instead of just counts.",
            "keywords": [
                "Quantum Computing",
                "Algorithms"
            ],
            "conversation_score": 5.0,
            "id": "new_convo_5.0_3"
        }
    },
    {
        "page_content": "How can I analyze brain waves? Context: This task involves Neuroscience and Data Analysis. Answer: You can use the Comprehensive Brain Wave Analysis skill. This skill uses the 'mne', 'scipy', and 'numpy' libraries to perform advanced analysis of brain waves from raw EEG data, including filtering and epoch extraction.",
        "metadata": {
            "type": "new_convo",
            "date": "2023-10-02T00:00:00",
            "UserInput": "How can I analyze brain waves?",
            "AgentOutputs": "Context: This task involves Neuroscience and Data Analysis.",
            "FinalConsensus": "Answer: You can use the Comprehensive Brain Wave Analysis skill. This skill uses the 'mne', 'scipy', and 'numpy' libraries to perform advanced analysis of brain waves from raw EEG data, including filtering and epoch extraction.",
            "keywords": [
                "Neuroscience",
                "Data Analysis"
            ],
            "conversation_score": 5.0,
            "id": "new_convo_5.0_4"
        }
    }


# ... (more data)
]
# Transforming JSON data to Document objects
documents = transform_to_documents(json_data)

# Your JSON data


print(documents)

