# -*- coding: utf-8 -*-
"""Tasker

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13r1mysreE9ZXUZwi5BDtTEmtxnCb6saH

# 0. Installs, Imports and API Keys
"""

# Commented out IPython magic to ensure Python compatibility.
# RUN THIS CELL FIRST!
# %pip install -q langchain==0.0.150 pypdf pandas matplotlib tiktoken textract transformers openai faiss-cpu

import os
import pandas as pd
import openai
import matplotlib.pyplot as plt
from transformers import GPT2TokenizerFast
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains.question_answering import load_qa_chain
from langchain.llms import OpenAI
from langchain.chains import ConversationalRetrievalChain

os.environ["OPENAI_API_KEY"] = ""

"""# 1. Loading txt file

---
"""

with open('movm.txt', 'r') as f:
    text = f.read()

# Step 3: Create function to count tokens
tokenizer = GPT2TokenizerFast.from_pretrained("gpt2")
def count_tokens(text: str) -> int:
    return len(tokenizer.encode(text))

# Step 4: Split text into chunks
text_splitter = RecursiveCharacterTextSplitter(
    # Set a really small chunk size, just to show.
    chunk_size = 512,
    chunk_overlap  = 24,
    length_function = count_tokens,
)
#d
chunks = text_splitter.create_documents([text])

# Result is many LangChain 'Documents' around 500 tokens or less (Recursive splitter sometimes allows more tokens to retain context)
type(chunks[0])

"""# 2. Embed text and store embeddings"""

# Get embedding model
embeddings = OpenAIEmbeddings()

# Create vector database
db = FAISS.from_documents(chunks, embeddings)


"""# 3. Setup retrieval function"""

# Check similarity search is working

# Create QA chain to integrate similarity search with user queries (answer query from knowledge base)

chain = load_qa_chain(OpenAI(temperature=0), chain_type="stuff")

#Uquery = input("request a movment: ")
#query = Uquery +"/###/ you are talking to a robot who has a paint brush , use ONLY and  the commanads in given  to solve the task if the task needs something not in the TXT then say you cant."
audio_file= open("math3.m4a", "rb")
# transcript = openai.Audio.transcribe("whisper-1", audio_file)
transcript = "draw a square"

#print(transcript)
query = transcript +"/###/ you are talking to a robot who has a paint brush , Make a combination of the commands EXACTLY seperated by a comma that when done in the order said it will complete the request, do NOT use a full stop at the end and make it all lower case"

docs = db.similarity_search(query)

commands = chain.run(input_documents=docs, question=query)

print(commands)

str = commands
str_list = str.split(', ')
leng = len(str_list)
str_list[0] = str_list[0][1:]
print(str_list)

for i in range(leng):
    command = str_list[i % len(str_list)]  # Cycle through commands list

    if command == 'jump':
        print("Jumping!")

    elif command == 'turn right':
        print("Turning right!")

    elif command == 'turn left':
        print("Turning left!")

    elif command == 'walk backward':
        print("Walking backward!")

    elif command == 'walk forward':
        print("Walking forward!")

    elif command == 'grab':
        print("Grabbing!")

    elif command == 'hold':
        print("Holding!")

    elif command == 'let go':
        print("Letting go!")

    elif command == 'start painting on the ground':
        print("Putting paint brush on the ground!")

    elif command == 'stop painting on the ground':
        print("Removing paint brush from the ground!")

    elif command == 'walk in a circle':
        print("Walking in a circle!")

    else:
        print("Command not recognized!")