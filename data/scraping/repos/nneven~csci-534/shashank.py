import librosa
import numpy as np
import whisper
import openai
import torch
import os
from dotenv import load_dotenv
import pickle 
load_dotenv()
openai.api_key = os.getenv("OPENAI_KEY")

# NOTE: if you change the image prompt
# {n}: number of prompts to generate
# {e}: emotion of the song
# {t}: themes/summary of lyrics
GPT_PROMPT = "Can you create a highly detailed prompt for the AI image generator Dall-E, each detail must be separated by a comma, which describes a scene in intricate detail adding artistic style, the light setting, artistic descriptive terms, and the mood of the imageInput Prompt: An album cover depicting {t}. The mood is {e}."

valence_model = pickle.load(open('./assets/valence_model', 'rb'))
arousal_model = pickle.load(open('./assets/arousal_model', 'rb'))
dominance_model = pickle.load(open('./assets/dominance_model', 'rb'))
scaler = pickle.load(open('./assets/scaler', 'rb'))

def extract_lyrics(song_file):
    """
    Takes song file and returns extracted lyrics

    (song_file) -> string
    """
    lyrics = ""

    model = whisper.load_model("base")
    result = model.transcribe(song_file)
    lyrics = result["text"]

    return lyrics


# NOTE: I'm not sure if lyric theme extration should return a list of themes or a paragraph summary
def extract_themes(lyrics):
    """
    Takes song lyrics and returns extracted themes

    (lyrics) -> [string]
    """
    song_themes = []

    # TODO: code to extract lyric themes/summary
    # NOTE: default just passes lyrics as themes
    song_themes.append(lyrics)

    return song_themes


def extract_emotion(y, sr):
    """
    Takes song data and returns extracted emotion

    (y, sr) -> string
    """
    audio_features = get_audio_features(y,sr)
    scaled_features = scaler.transform([audio_features])
    predicted_valence = valence_model.predict(scaled_features[0].reshape(1, -1)).flatten()
    predicted_arousal =  arousal_model.predict(scaled_features[0].reshape(1, -1)).flatten()
    predicted_dominance = dominance_model.predict(scaled_features[0].reshape(1, -1)).flatten()
    print("Predicted emotion label", get_emotion_label(predicted_valence, predicted_arousal, predicted_dominance))
    return get_emotion_label(predicted_valence, predicted_arousal, predicted_dominance)

def get_audio_features(y,sr):
    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)
    rmse = librosa.feature.rms(y=y)
    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)
    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)
    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)
    zcr = librosa.feature.zero_crossing_rate(y)
    mfcc = librosa.feature.mfcc(y=y, sr=sr)
    audio_features = [np.mean(chroma_stft), np.mean(rmse), np.mean(spec_cent), np.mean(spec_bw),np.mean(rolloff),np.mean(zcr)]
    for e in mfcc:
        audio_features.append(np.mean(e))
    return audio_features     

def get_emotion_label(valence,arousal,dominance):
    if valence > 0.62:
        if arousal > 0.6:
            if dominance > 0.7:
                return "Happiness"
            else:
                return "Surprise"
        else:
            if dominance > 0.6:
                return "Happiness"
            else:
                return "Neutral"
    else:
        if arousal > 0.6:
            if dominance > 0.69:
                return "Anger"
            else:
                return "Fear"
        else:
            if dominance > 0.69:
                return "Sadness"
            else:
                return "Blues"

# NOTE: Ways to increase the number of images generated
# increase numPrompts: increaes the number of image_prompts generated by chatGPT
# increase numImages: increases the number of Images generated for each image_prompt


def generate_prompts(themes, emotion, gpt_prompt, num_prompts):
    """
    Takes extracted themes and emotion, plugs them into gpt_prompt, sends to chatGPT numPrompts times, and returns the generated image_prompt(s)

    (themes, emotion, numPrompts) -> [string]
    """

    image_prompts = []

    # Use the format() method to replace the placeholders in gpt_prompt with values
    gpt_prompt = gpt_prompt.format(t=themes, e=emotion)

    # Call GPT-3
    response = openai.Completion.create(
        engine="text-davinci-003",
        prompt=gpt_prompt,
        max_tokens=256,
        n=num_prompts,
        stop=None,
        temperature=0.8,
    )

    # Extract and print the image description
    for i in range(num_prompts):
        image_prompts.append(response.choices[i].text.strip())

    print(image_prompts)

    return image_prompts


def generate_images(image_prompts, num_images):
    """
    Takes image_prompts and returns numImages images generated per prompt

    (image_prompt, numImages) -> [image]
    """

    images = []

    for i in range(len(image_prompts)):
        response = openai.Image.create(
            prompt=image_prompts[i], n=num_images, size="1024x1024"
        )

        for j in range(num_images):
            images.append(response["data"][j]["url"])

    return images
