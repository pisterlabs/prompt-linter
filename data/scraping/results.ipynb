{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üï∏Ô∏è Scraping Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result Counts from Github (Collected Manually)\n",
      "    openai: 71.7k\n",
      "    langchain: 50.2k\n",
      "    cohere: 5.1k\n",
      "    guidance: 1.6k\n",
      "    anthropic: 1.5k\n",
      "    llamaindex: 91\n",
      "\n",
      "Library: openai\n",
      "\tTotal number of results: 33952\n",
      "\tTotal number of hrefs: 18206\n",
      "Library: langchain\n",
      "\tTotal number of results: 28803\n",
      "\tTotal number of hrefs: 16775\n",
      "Library: cohere\n",
      "\tTotal number of results: 5380\n",
      "\tTotal number of hrefs: 4121\n",
      "Library: llamaindex\n",
      "\tTotal number of results: 91\n",
      "\tTotal number of hrefs: 91\n",
      "Library: guidance\n",
      "\tTotal number of results: 1303\n",
      "\tTotal number of hrefs: 1195\n",
      "Library: anthropic\n",
      "\tTotal number of results: 1401\n",
      "\tTotal number of hrefs: 1328\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "libraries = [\"openai\", \"langchain\", \"cohere\", \"llamaindex\", \"guidance\", \"anthropic\"]\n",
    "\n",
    "print(\n",
    "\"\"\"\n",
    "Result Counts from Github (Collected Manually)\n",
    "    openai: 71.7k\n",
    "    langchain: 50.2k\n",
    "    cohere: 5.1k\n",
    "    guidance: 1.6k\n",
    "    anthropic: 1.5k\n",
    "    llamaindex: 91\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "all_hrefs = []\n",
    "for lib in libraries:\n",
    "    with open(f'results_{lib}.json') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    total_num_results = 0\n",
    "    total_hrefs = 0\n",
    "\n",
    "    for charCombo, results in data.items():\n",
    "        num_result = results['num_results']\n",
    "        hrefs = results['hrefs']\n",
    "\n",
    "        # Convert num_result to int\n",
    "        num_result = num_result.split()[0].replace(',', '')\n",
    "        num_result = int(float(num_result[:-1])) if \"k\" in num_result else int(num_result)\n",
    "        total_num_results += num_result\n",
    "\n",
    "        # Count hrefs\n",
    "        total_hrefs += len(hrefs)\n",
    "        all_hrefs += hrefs\n",
    "\n",
    "    print(f'Library: {lib}')\n",
    "    print('\\tTotal number of results:', total_num_results)\n",
    "    print('\\tTotal number of hrefs:', total_hrefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö Downloading All Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of hrefs: 41716\n",
      "0 100 200 300 400 500 600 700 800 900 1000 Error:  404 repos/supertimmyh~vidsum pages~4_Summarizing_Video.py\n",
      "1100 1200 1300 1400 1500 1600 1700 1800 1900 HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out. (read timeout=1)\n",
      "Error:  repos/mikrl~django-llm llm~admin.py\n",
      "2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 3400 3500 3600 3700 3800 Error:  404 repos/TheseApps~Prompts gptCalls01~callGpt.py\n",
      "3900 4000 4100 Error:  404 repos/rixmape~drr-chatbot cli-sample-usage.py\n",
      "4200 4300 4400 4500 4600 Error:  404 repos/christina8711~llm_cubestacking CubeStackingAssistant.py\n",
      "4700 4800 4900 5000 5100 5200 5300 5400 5500 5600 5700 5800 5900 6000 6100 6200 6300 6400 6500 6600 6700 6800 HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out. (read timeout=1)\n",
      "Error:  repos/uqarni~reposite-demo functions.py\n",
      "6900 7000 7100 7200 7300 7400 Error:  404 repos/Sea-Snell~LLM_RL llm_rl_scripts~chess~gpt4~gpt4_chess_endgames.py\n",
      "7500 7600 7700 7800 7900 Error:  404 repos/tk1363704~TA2_manager hetao_subteam1_known_norms.py\n",
      "Error:  404 repos/tk1363704~TA2_manager hetao_subteam1.py\n",
      "8000 8100 8200 8300 8400 8500 8600 8700 8800 8900 Error:  404 repos/JerryWestrick~KnowledgeEngineer KbServerApp~kbserver.py\n",
      "9000 Error:  404 repos/danieljbk~calhacks-spot code~legacy~key.py\n",
      "9100 9200 9300 9400 Error:  404 repos/ken-at-kore~LG-AiBot-Prototype lg_aibot.py\n",
      "9500 9600 9700 9800 9900 10000 10100 10200 10300 Error:  404 repos/tk1363704~TA2_manager monash_norm_detector.py\n",
      "10400 10500 Error:  404 repos/jayantr7~saatvaChatbot myEmbeddings.py\n",
      "Error:  404 repos/jayantr7~saatvaChatbot myEmbeddings_copy.py\n",
      "10600 Error:  404 repos/prixingcha~voice-narrator narrator.py\n",
      "10700 10800 10900 11000 Error:  404 repos/tk1363704~TA2_manager norm_violation_detection.py\n",
      "11100 11200 11300 11400 11500 11600 11700 Error:  404 repos/Leoyishou~viva output~outputTest.py\n",
      "11800 11900 Error:  404 repos/Sea-Snell~LLM_RL llm_rl_scripts~car_dealer~env~personality_convos.py\n",
      "12000 12100 12200 12300 12400 Error:  404 repos/Sea-Snell~LLM_RL llm_rl_scripts~twenty_questions~env~policies.py\n",
      "12500 Error:  404 repos/jayantr7~saatvaChatbot prompter.py\n",
      "12600 12700 12800 12900 13000 13100 Error:  404 repos/tk1363704~TA2_manager ranker.py\n",
      "13200 13300 13400 13500 13600 Error:  404 repos/tk1363704~TA2_manager run_gpt3_corrector_remediator.py\n",
      "13700 13800 13900 14000 14100 14200 14300 14400 14500 Error:  404 repos/danieljbk~calhacks-spot speech_to_cmd.py\n",
      "Error:  404 repos/danieljbk~calhacks-spot code~legacy~voice~spot.py\n",
      "14600 Error:  404 repos/abstra-app~hackerforms-examples forms~sql_generator.py\n",
      "14700 14800 14900 15000 15100 15200 15300 15400 15500 15600 15700 15800 15900 16000 Error:  404 repos/Sea-Snell~LLM_RL llm_rl_scripts~twenty_questions~misc~twenty_questions_gpt4.py\n",
      "16100 16200 16300 16400 16500 Error:  404 repos/simular-ai~OpenAGI vision.py\n",
      "16600 16700 16800 16900 17000 17100 17200 17300 17400 17500 17600 17700 17800 17900 18000 18100 18200 18300 18400 18500 18600 18700 18800 18900 19000 19100 19200 19300 19400 19500 19600 19700 19800 19900 20000 20100 20200 20300 Error:  404 repos/Leoyishou~viva real_tools~AskAgainTool.py\n",
      "Error:  404 repos/Leoyishou~viva chains~AsyncChain.py\n",
      "20400 20500 20600 20700 20800 20900 21000 21100 21200 21300 Error:  404 repos/hsushuai~LangChain-Chat-Demo chat_models~call_chat_models.py\n",
      "Error:  404 repos/hsushuai~LangChain-Chat-Demo vector_stores~call_vectorstore.py\n",
      "21400 21500 21600 21700 21800 21900 22000 22100 22200 22300 22400 22500 22600 22700 22800 22900 23000 23100 23200 23300 23400 23500 23600 Error:  404 repos/BastinFlorian~RAG-GCP src~chatbot~firestore.py\n",
      "23700 23800 23900 24000 24100 24200 HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out. (read timeout=1)\n",
      "Error:  repos/karancode~langchain langchain~document_loaders~googledrive.py\n",
      "24300 24400 24500 24600 24700 24800 24900 25000 25100 25200 25300 25400 25500 Error:  404 repos/Leoyishou~viva experiments~iteratorTest.py\n",
      "25600 25700 25800 Error:  404 repos/ShelbyJenkins~langchain langchain~document_loaders~iugu.py\n",
      "25900 26000 26100 26200 26300 26400 26500 26600 26700 Error:  404 repos/ken-at-kore~LG-AiBot-Prototype lg_aibot.py\n",
      "26800 26900 27000 27100 27200 27300 27400 27500 27600 27700 27800 Error:  404 repos/Leoyishou~viva agents~multiActionAgent.py\n",
      "27900 28000 Error:  404 repos/jfelipenc~NexbotChat backend~nexbot.py\n",
      "28100 28200 28300 28400 28500 28600 Error:  404 repos/ziphell~OpenCopilot llm-server~routes~workflow~openapi_agent.py\n",
      "28700 28800 28900 29000 29100 29200 29300 29400 29500 29600 29700 29800 29900 30000 30100 30200 30300 30400 30500 Error:  404 repos/reinhardtpalko~auto-ratings question-rubric-create~rubric_setup.py\n",
      "30600 30700 Error:  404 repos/davidlainesv~olivia-finetuning sabana_update.py\n",
      "30800 Error:  404 repos/Leoyishou~viva agents~scheduleAgent.py\n",
      "30900 31000 31100 31200 31300 31400 31500 31600 31700 31800 31900 32000 32100 32200 32300 32400 32500 32600 32700 32800 Error:  404 repos/Leoyishou~viva viva2.py\n",
      "32900 33000 33100 33200 33300 33400 33500 33600 33700 33800 33900 34000 Error:  404 repos/ziphell~OpenCopilot llm-server~routes~workflow~workflow_controller.py\n",
      "34100 Error:  404 repos/ziphell~OpenCopilot llm-server~routes~workflow~workflow_controller.py\n",
      "34200 34300 34400 34500 Error:  404 repos/ShelbyJenkins~langchain langchain~document_loaders~xorbits.py\n",
      "34600 34700 34800 34900 Error:  404 repos/hsushuai~LangChain-Chat-Demo embeddings~zhipuai_embeddings.py\n",
      "35000 35100 35200 35300 35400 35500 35600 35700 35800 35900 36000 36100 36200 36300 36400 HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out. (read timeout=1)\n",
      "Error:  repos/saarmichael~My-CoG PyCoG~flask_app~src~main~tools~export_data.py\n",
      "36500 [Errno 36] File name too long: 'repos/openFudan~fudan-coursera/3.%E4%B8%93%E4%B8%9A%E6%95%99%E8%82%B2~%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF~%E4%B8%93%E4%B8%9A%E5%BF%85%E4%BF%AE~%E6%AF%95%E4%B8%9A%E8%AE%BA%E6%96%87~%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E6%A0%B7%E4%BE%8B~dltc%20with%20gensim%20lda~gensim%20lda.py'\n",
      "Error:  repos/openFudan~fudan-coursera 3.%E4%B8%93%E4%B8%9A%E6%95%99%E8%82%B2~%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF~%E4%B8%93%E4%B8%9A%E5%BF%85%E4%BF%AE~%E6%AF%95%E4%B8%9A%E8%AE%BA%E6%96%87~%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E6%A0%B7%E4%BE%8B~dltc%20with%20gensim%20lda~gensim%20lda.py\n",
      "36600 36700 36800 36900 [Errno 36] File name too long: 'repos/openFudan~fudan-coursera/3.%E4%B8%93%E4%B8%9A%E6%95%99%E8%82%B2~%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF~%E4%B8%93%E4%B8%9A%E5%BF%85%E4%BF%AE~%E6%AF%95%E4%B8%9A%E8%AE%BA%E6%96%87~%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E6%A0%B7%E4%BE%8B~dltc%20with%20gensim%20lda~lda%20with%20more%20dataset.py'\n",
      "Error:  repos/openFudan~fudan-coursera 3.%E4%B8%93%E4%B8%9A%E6%95%99%E8%82%B2~%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF~%E4%B8%93%E4%B8%9A%E5%BF%85%E4%BF%AE~%E6%AF%95%E4%B8%9A%E8%AE%BA%E6%96%87~%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E6%A0%B7%E4%BE%8B~dltc%20with%20gensim%20lda~lda%20with%20more%20dataset.py\n",
      "37000 37100 HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out. (read timeout=1)\n",
      "Error:  repos/l0di~openai_spotify source~logic.py\n",
      "37200 37300 37400 37500 37600 37700 37800 37900 38000 38100 [Errno 36] File name too long: 'repos/openFudan~fudan-coursera/3.%E4%B8%93%E4%B8%9A%E6%95%99%E8%82%B2~%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF~%E4%B8%93%E4%B8%9A%E5%BF%85%E4%BF%AE~%E6%AF%95%E4%B8%9A%E8%AE%BA%E6%96%87~%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E6%A0%B7%E4%BE%8B~dltc%20with%20gensim%20lda~simple%20gensim%20lda.py'\n",
      "Error:  repos/openFudan~fudan-coursera 3.%E4%B8%93%E4%B8%9A%E6%95%99%E8%82%B2~%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF~%E4%B8%93%E4%B8%9A%E5%BF%85%E4%BF%AE~%E6%AF%95%E4%B8%9A%E8%AE%BA%E6%96%87~%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E6%A0%B7%E4%BE%8B~dltc%20with%20gensim%20lda~simple%20gensim%20lda.py\n",
      "38200 38300 38400 38500 38600 38700 38800 38900 39000 39100 39200 39300 39400 HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out. (read timeout=1)\n",
      "Error:  repos/kajarenc~streamlit-guidance app.py\n",
      "39500 39600 HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out. (read timeout=1)\n",
      "Error:  repos/Azure-Samples~miyagi services~expense-service~python~orchestration~guidance.py\n",
      "HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out. (read timeout=1)\n",
      "Error:  repos/NCATS-Tangerine~CPKG fhirclient~models~guidanceresponse_tests.py\n",
      "39700 HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out. (read timeout=1)\n",
      "Error:  repos/all-of-us~raw-data-repository rdr_service~lib_fhir~fhirclient_3_0_0~models~guidanceresponse_tests.py\n",
      "HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out. (read timeout=1)\n",
      "Error:  repos/jonnycrunch~fhir-2 py~google~fhir~r4~json_format_test.py\n",
      "HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out. (read timeout=1)\n",
      "Error:  repos/andysalerno~guider llama_awk.py\n",
      "HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out. (read timeout=1)\n",
      "Error:  repos/hackkhai~blend_diffusers src~diffusers~pipelines~stable_diffusion_xl~lpw.py\n",
      "39800 HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out. (read timeout=1)\n",
      "Error:  repos/prushto~cs236 examples~community~lpw_stable_diffusion_xl.py\n",
      "HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out. (read timeout=1)\n",
      "Error:  repos/usdot-fhwa-stol~carma-platform guidance_plugin_validator~src~guidance_plugin_validator~main.py\n",
      "HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out. (read timeout=1)\n",
      "Error:  repos/eileenforwhat~dream-control-3d main.py\n",
      "HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out. (read timeout=1)\n",
      "Error:  repos/jclarkk~dreamgaussian main.py\n",
      "HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out. (read timeout=1)\n",
      "Error:  repos/Tlooh~Improved_diffusion loss_compare~mmline.py\n",
      "39900 HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out.\n",
      "Error:  repos/wyz894272237~diffusers src~diffusers~pipelines~stable_diffusion_xl~pipeline_stable_diffusion_xl.py\n",
      "HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out. (read timeout=1)\n",
      "Error:  repos/willlllllio~diffusers src~diffusers~pipelines~stable_diffusion_xl~pipeline_stable_diffusion_xl_img2img.py\n",
      "HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out. (read timeout=1)\n",
      "Error:  repos/DearFloyd~diffusers src~diffusers~pipelines~stable_diffusion_xl~pipeline_stable_diffusion_xl_inpaint.py\n",
      "40000 HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out. (read timeout=1)\n",
      "Error:  repos/ChatFAQ~ChatFAQ chat_rag~chat_rag~inf_retrieval~query_generator.py\n",
      "HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out. (read timeout=1)\n",
      "Error:  repos/conql~linuxbot-data exp~qwen_zeroshot_old.py\n",
      "HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out. (read timeout=1)\n",
      "Error:  repos/XEun-0~robosub-ROS state_machine~src~real_smach.py\n",
      "40100 HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Read timed out. (read timeout=1)\n",
      "Error:  repos/arpg~marble_frontier FastMarching3D_ROS~src~subt_tf2odom.py\n",
      "40200 40300 40400 40500 40600 40700 40800 40900 41000 41100 41200 Error:  404 repos/danielgross~python-llm llm~main.py\n",
      "41300 41400 41500 41600 41700 Done\n"
     ]
    }
   ],
   "source": [
    "import os, requests\n",
    "\n",
    "print('\\nTotal number of hrefs:', len(all_hrefs))\n",
    "\n",
    "all_rawFileURLs = [href.replace(\"blob/\", \"\").replace(\"https://github.com\", \"https://raw.githubusercontent.com\") for href in all_hrefs]\n",
    "for i in range(len(all_rawFileURLs)):\n",
    "    if \"#\" in all_rawFileURLs[i]:\n",
    "        all_rawFileURLs[i] = \"#\".join(all_rawFileURLs[i].split(\"#\")[:-1])\n",
    "\n",
    "root_dir = \"repos\"\n",
    "if not os.path.exists(root_dir):\n",
    "    os.mkdir(root_dir)\n",
    "\n",
    "count = 0\n",
    "for url in all_rawFileURLs:\n",
    "    url_split = url.split(\"/\")\n",
    "\n",
    "    # Getting repo name\n",
    "    repo_name = \"~\".join(url_split[3:5])\n",
    "\n",
    "    # Remove \"#\" from filename if it exists\n",
    "    filename_addr = url_split[6:]\n",
    "    filename_addr = \"~\".join(filename_addr)\n",
    "\n",
    "    # repo path\n",
    "    repo_path = os.path.join(root_dir, repo_name)\n",
    "    if not os.path.exists(repo_path):\n",
    "        os.mkdir(os.path.join(root_dir, repo_name))\n",
    "\n",
    "    # file path\n",
    "    file_path = os.path.join(repo_path, filename_addr)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        try:\n",
    "            r = requests.get(url, timeout=1)\n",
    "            # Exception thrown before file is created. \n",
    "            # So, if file exists, it's safe to assume that it's been downloaded successfully.\n",
    "            if r.status_code == 200:\n",
    "                with open(file_path, \"w\") as f:\n",
    "                    f.write(r.text)\n",
    "            else:\n",
    "                print(\"Error: \", r.status_code, repo_path, filename_addr)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Error: \", repo_path, filename_addr)\n",
    "\n",
    "    if count % 100 == 0:\n",
    "        print(count, end=\" \")\n",
    "    count += 1\n",
    "\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
