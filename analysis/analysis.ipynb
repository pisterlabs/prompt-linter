{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Repo Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1127\n",
      "577\n"
     ]
    }
   ],
   "source": [
    "# TODO: Discuss idea with Professor\n",
    "# Q. What high prompt-density repositories should we be looking at? And, for which parsers?\n",
    "\n",
    "# USING DEFAULT PARSER for now\n",
    "import json\n",
    "with open('../parse_data/repo_to_prompts.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "all_prompts = []\n",
    "high_density_repo_prompts = []\n",
    "for repo in data:\n",
    "    all_prompts.extend(data[repo])\n",
    "    if len(data[repo]) > 10:\n",
    "        high_density_repo_prompts.extend(data[repo])\n",
    "\n",
    "print(len(all_prompts))\n",
    "print(len(high_density_repo_prompts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving prompts to files so that cspell can check them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "root_dir = 'repos_temp'\n",
    "# Make repo_temp\n",
    "if not os.path.exists(root_dir):\n",
    "    os.makedirs(root_dir)\n",
    "    for repo in data:\n",
    "        filename = f\"{repo}.py\"\n",
    "        path = os.path.join(root_dir, filename)\n",
    "        with open(path, 'w') as f:\n",
    "            f.writelines(data[repo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['cspell', 'repos_temp/836304831~langchain-anal.py'], returncode=0)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# file_to_check = \"repos_temp/836304831~langchain-anal.py\"\n",
    "subprocess.run([\"cspell\", \"repos_temp/836304831~langchain-anal.py\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Text Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(high_density_repo_prompts)\n",
    "df.columns = ['prompts']\n",
    "\n",
    "df.to_csv('high_density_repo_prompts.csv', index=False)\n",
    "\n",
    "count = 0\n",
    "for prompt in high_density_repo_prompts:\n",
    "    if \"assistant\" in prompt.lower() or \"assistent\" in prompt.lower():\n",
    "        count += 1\n",
    "        # print(prompt)\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ❌ **Spell Check** (FAILED) (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "[('AI', 289), (\"'s\", 274), (\"n't\", 172), ('If', 172), ('This', 91), ('Let', 84), ('Do', 77), ('We', 72), ('pl', 72), ('json', 68), ('template', 64), ('Make', 63), ('No', 60), ('url', 53), ('llm', 48), ('api', 48), ('What', 44), ('openai', 43), ('ui', 42), ('Here', 41), (\"'m\", 39), ('inputs', 38), ('Tool', 37), ('Inputs', 36), ('OF', 34), ('Get', 33), ('blog', 33), ('How', 32), ('Modal', 32), ('python', 30), ('My', 30), ('Mora', 30), ('Rivera', 30), (\"'ui\", 28), ('Pay', 27), ('doc', 27), ('website', 27), ('func', 22), ('tweet', 22), ('str', 22), ('implemented', 22), (\"'S\", 22), ('Task', 21), ('Be', 21), ('qubits', 21), ('formatting', 20), ('annotation', 20), ('interfaces', 20), ('UX', 20), ('integrations', 20), ('loader', 19), ('Load', 19), ('schema', 19), ('单位', 19), ('generated', 18), ('alt', 18), ('Name', 18), ('params', 18), ('York', 17), ('math', 16), ('elif', 16), (\"'prompt\", 16), ('argilla', 16), ('None', 15), ('prompts', 15), ('As', 15), ('Waiver', 15), ('waiver', 15), ('illegality', 15), ('Independents', 15), ('unwavering', 15), ('Putin', 15), ('retirees', 15), ('homeland', 15), ('reset', 15), ('funerals', 15), ('Wilbert', 15), ('Jason', 15), ('sanctions', 15), ('targeted', 15), ('businesses', 15), ('informative', 15), ('https', 15), (\"'sk\", 14), (\"'Please\", 14), ('specifies', 14), ('robot', 14), ('suv', 14), ('quiz', 14), ('OK', 14), ('snippet', 14), ('criteria', 14), ('outputs', 13), ('dir', 13), ('transcript', 13), ('An', 13), ('Structured', 13), ('uploaded', 12), ('factual', 12), ('queries', 12), ('ids', 12), ('trending', 12), ('NO', 12), ('comp', 12), ('attr', 12), ('statement1', 12), ('statement2', 12), ('transformers', 11), ('sql', 11), ('spec', 11), ('py', 11), ('grading', 11), ('Chat', 11), ('Cypher', 11), ('Wrap', 11), ('identifiers', 11), ('DB', 10), ('spinner', 10), ('config', 10), ('browser', 10), ('rephrase', 10), ('fob', 10), ('gpt', 9), ('turbo', 9), (\"'doc\", 9), ('Robot', 9), ('Then', 9), ('Schema', 9), ('Grade', 9), ('phrasing', 9), ('eq', 9), ('msgs', 8), ('16k', 8), ('verbose', 8), ('cb', 8), ('Show', 8), ('parameters', 8), ('pretrained', 8), (\"'ll\", 8), ('relayed', 8), ('nouns', 8), ('coreference', 8), ('param', 8), ('calculator', 8), ('微博', 8), ('weibo', 8), ('placeholder', 7), ('Keep', 7), ('Find', 7), ('tuple', 7), (\"'re\", 7), ('insights', 7), ('End', 7), ('specifications', 7), ('Better', 7), ('Pears', 7), ('img', 7), ('OR', 7), ('TO', 7), ('gt', 7), ('temp', 6), (\"'Notion\", 6), ('qubit', 6), ('evolving', 6), ('Where', 6), ('xml', 6), ('preferences', 6), ('foaf', 6), ('trendy', 6), (\"'trending\", 6), (\"'True\", 6), ('filtering', 6), ('MM', 6), ('DD', 6), ('typed', 6), ('int', 6), (\"'Recommend\", 6), ('Args', 5), ('dict', 5), ('rm', 5), ('ppo', 5), ('dpo', 5), ('querying', 5), ('Setup', 5), ('Ball', 5), ('google', 5), ('db', 5), ('genre', 5), ('pred', 5), ('append', 4), ('chunk', 4), ('initialize', 4), ('shutil', 4), ('Notion', 4), ('app', 4), ('variables', 4), ('guidelines', 4), ('tuples', 4), ('bert', 4), ('sft', 4), ('Dict', 4), ('trl', 4), ('gpt2', 4), ('tensors', 4), ('pt', 4), ('eos', 4), ('snippets', 4), ('generates', 4), ('catkin', 4), ('setup', 4), ('entities', 4), ('powered', 4), ('Sam', 4), ('Ali', 4), ('So', 4), ('simplified', 4), ('scroll', 4), ('Store', 4), ('Gmail', 4), ('apps', 4), ('Dorsia', 4), ('8pm', 4), ('dorsia', 4), ('opentable', 4), ('Cuisine', 4), ('stg', 4), ('Lookup', 4), ('lookup', 4), ('atop', 4), ('Cape', 4), ('Alava', 4), ('meters', 4), ('US', 4), ('IF', 4), ('assertions', 4), ('eval', 4), ('元的', 4), ('指令', 4), ('dungeons', 4), ('dragons', 4), ('tempfile', 3), ('suffix', 3), ('typing', 3), ('validations', 3), ('caller', 3), ('summarizer', 3), ('translates', 3), ('releated', 3), ('kwargs', 3), ('ratings', 3), ('decode', 3), ('options', 3), ('parsed', 3), ('请说', 3), ('问题', 3), ('manipulating', 3), ('worsens', 3), ('Larry', 3), ('Hey', 3), ('Alan', 3), ('Turing', 3), ('Newmark', 3), ('Jaws', 3), ('Casino', 3), ('Date', 3), ('Doe', 3), ('coding', 3), ('semantically', 3), ('documented', 3), ('Fake', 3), ('retry', 3), ('interacting', 3), ('Base', 3), (\"'d\", 3), ('assists', 3), ('fetches', 3), ('Katy', 3), ('Perry', 3), ('lt', 3), ('MS', 3), ('Fact', 3), ('输入', 3), ('Letting', 3), ('uploader', 2), ('cursor', 2), ('parsing', 2), ('llms', 2), ('isdir', 2), ('rmtree', 2), ('unzip', 2), ('loaders', 2), ('docstore', 2), ('directives', 2), ('chatbot', 2), ('aligns', 2), ('selects', 2), ('L6', 2), ('v2', 2), ('num', 2), ('spacy', 2), ('lang', 2), ('gpu', 2), ('uuid4', 2), ('logits', 2), ('专业', 2), ('TL', 2), ('DR', 2), ('Hi', 2), (\"'ve\", 2), ('png', 2), ('contacting', 2), ('Swarm', 2), ('landscapes', 2), ('concludes', 2), ('extracting', 2), (\"'share\", 2), ('maintainer', 2), ('cfg', 2), ('lib', 2), ('triplets', 2), ('Steven', 2), ('Korean', 2), ('Bengali', 2), ('UP', 2), ('AK', 2), ('redfin', 2), ('nyc', 2), ('Picker', 2), ('EN', 2), ('logo', 2), ('selector', 2), ('Sep', 2), ('PM', 2), ('Location', 2), ('factually', 2), ('catchy', 2), ('Newell', 2), (\"'Identification\", 2), (\"'Value\", 2), (\"'Other\", 2), (\"'Result\", 2), (\"'Goal\", 2), ('Decompose', 2), ('choices', 2), ('Goal', 2), ('updating', 2), ('dbt', 2), ('cleans', 2), ('classifying', 2), ('cobol', 2), ('assessing', 2), (\"'The\", 2), ('II', 2), ('Kùzu', 2), ('triples', 2), ('xmlns', 2), ('prefixes', 2), ('rewrite', 2), ('table1', 2), ('table2', 2), ('table3', 2), ('Names', 2), ('detections', 2), ('classifications', 2), ('sim', 2), ('我是', 2), ('道德', 2), ('示例', 2), ('人类', 2), ('因此', 2), ('Dungeons', 2), ('Dragons', 2), ('acces', 2), (\"'Provide\", 2), (\"'Diagnose\", 2), (\"'Create\", 2), ('brwn', 1), ('jmps', 1), ('lze', 1), ('nad', 1), ('streamlit', 1), ('sidebar', 1), ('sk', 1), ('getenv', 1), ('identifier', 1), ('predefined', 1), ('Blogger', 1), ('blogger', 1), ('Chatbot', 1), (\"'summarize\", 1), ('upload', 1), ('Cloud', 1), ('setfit', 1), ('peft', 1), ('sm', 1), ('uuid', 1), ('Iterator', 1), ('rated', 1), ('Text', 1), ('toad', 1), ('RM', 1), ('sequences', 1), ('padding', 1), ('grad', 1), ('Constraints', 1), ('专家', 1), ('语句', 1), ('注意', 1), ('查询', 1), ('使用', 1), ('格式', 1), ('randomly', 1), ('Role', 1), ('modules', 1), ('seperatedly', 1), ('frontend', 1), ('backend', 1), ('utils', 1), ('init', 1), ('3rd', 1), ('libs', 1), ('bcrypt', 1), (\"'game\", 1), ('Facts', 1), ('Emoji', 1), ('Pick', 1), ('emoji', 1), ('Can', 1), ('processed', 1), ('fabricate', 1), ('faking', 1), ('fake', 1), ('开始', 1), ('On', 1), ('Flow', 1), ('blogs', 1), ('dialogues', 1), ('tailored', 1), ('ony', 1), ('demo', 1), ('reiterate', 1), ('generating', 1), ('focusing', 1), ('automating', 1), ('pave', 1), ('repetitive', 1), ('automated', 1), ('professionals', 1), ('databases', 1), ('confidentiality', 1), ('implications', 1), ('Drafting', 1), ('templates', 1), ('jargon', 1), ('edits', 1), ('collaborations', 1), ('updates', 1), ('outcomes', 1), ('assessments', 1), ('streamline', 1), ('clarified', 1), ('sensors', 1), ('subset', 1), ('placeholders', 1), ('unsure', 1), ('publishes', 1), ('subscribes', 1), ('launches', 1), ('compiled', 1), (\"'add\", 1), ('executable', 1), ('CMake', 1), ('maintainers', 1), ('ament', 1), (\"'resource\", 1), (\"'package\", 1), ('scripts', 1), (\"'You\", 1), ('1万', 1), ('followup', 1), ('existent', 1), ('Embeddings', 1), ('generator', 1), ('surreal', 1), ('bash', 1), ('succint', 1), ('completes', 1), (\"'Decomposition\", 1), (\"'Analogy\", 1), ('retrieval', 1), ('structured', 1), ('taboos', 1), ('ingredients', 1), ('inluding', 1), ('recomendation', 1), ('burger', 1), ('pizza', 1), ('Preference', 1), ('replica', 1), ('Snowflake', 1), ('pc', 1), ('rdeb', 1), ('staging', 1), ('cancelled', 1), ('deleted', 1), (\"'placed\", 1), (\"'shipped\", 1), (\"'completed\", 1), (\"'return\", 1), (\"'returned\", 1), ('reviewer', 1), ('exerpts', 1), ('comversation', 1), ('scenarios', 1), ('Medicare', 1), ('federally', 1), ('programmer', 1), ('withing', 1), ('Code', 1), ('AS', 1), ('IS', 1), ('DO', 1), ('Craft', 1), ('cypher', 1), ('Foo', 1), ('Bar', 1), ('diff', 1), ('deleting', 1), ('mbox', 1), (\"'jane\", 1), ('Jane', 1), ('Spark', 1), (\"'now\", 1), ('Clic', 1), ('audio', 1), ('io', 1), ('Hmm', 1), ('答案', 1), ('Lyrics', 1), ('integer', 1), ('rap', 1), ('Entities', 1), ('idempotent', 1), ('indices', 1), ('vit', 1), ('base32', 1), ('Classes', 1), ('Class', 1), ('computes', 1), ('metrics', 1), ('TP', 1), ('FP', 1), ('FNs', 1), ('花名', 1), ('颜色', 1), ('请用', 1), ('结束', 1), ('同时', 1), ('首先', 1), ('而且', 1), ('assitiant', 1), ('inline', 1), ('ON', 1), ('SO', 1), ('Say', 1), ('zoomed', 1), ('atmospheric', 1), ('potions', 1), ('matte', 1), ('colorful', 1), ('closeup', 1), ('shoud', 1), ('Car', 1), ('Genre', 1), ('Mood', 1), ('Rating', 1), ('Crop', 1), ('Ingredients', 1), (\"'Generate\", 1), ('itinerary', 1), (\"'Resolve\", 1), ('Ticket', 1), ('ID', 1), (\"'Schedule\", 1), ('Sport', 1), ('Fitness', 1), ('Cooking', 1)]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from textblob import TextBlob, Word\n",
    "from spacy.language import Language\n",
    "import re\n",
    "\n",
    "misspelled_freq = {}\n",
    "@Language.component(\"spellcheck_component\")\n",
    "def spellcheck_component(doc):\n",
    "    # Use TextBlob to find misspelled words\n",
    "    # Initialize TextBlob with the text of the entire spaCy document\n",
    "    blob = TextBlob(doc.text)\n",
    "\n",
    "    for word in blob.words:\n",
    "        # Use TextBlob's Word object for spellchecking\n",
    "        w = Word(word)\n",
    "        # If the word is misspelled, TextBlob will have a suggestion with higher confidence\n",
    "        if w.correct() == word:\n",
    "            continue\n",
    "        # Add the misspelled word to our dictionary with its frequency\n",
    "        misspelled_freq[word] = misspelled_freq.get(word, 0) + 1\n",
    "            \n",
    "    # for word in misspelled:\n",
    "    #     misspelled_freq[word] = misspelled_freq.get(word, 0) + 1\n",
    "\n",
    "    # Return the doc following spaCy's pipeline component requirements\n",
    "    return doc\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Add spell-checking component to the pipeline\n",
    "nlp.add_pipe(\"spellcheck_component\")\n",
    "\n",
    "text = \"The quick brwn fox jmps over the lze dog.\"\n",
    "\n",
    "# Process the text with spaCy and check spelling\n",
    "nlp(text)\n",
    "\n",
    "count = 0\n",
    "for prompt in high_density_repo_prompts:\n",
    "    modified_string = re.sub(r'((\\{+)(\\s*)(.*?)(\\s*)(\\}+))', ' ', prompt)  # remove {variable}\n",
    "    modified_string = re.sub(r'\\\\n', ' ', modified_string)  # to avoid \"\\nTonight\"\n",
    "    modified_string = re.sub(r\"[^\\w']+\", \" \", modified_string)  # to avoid \"good-morning\" but words like keep \"don't\"\n",
    "    modified_string = re.sub(r\"_+\", \" \", modified_string)  # to avoid \"______\" or \"good__morning\"\n",
    "    doc = nlp(modified_string)\n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        print(count)\n",
    "\n",
    "\n",
    "print(sorted(misspelled_freq.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🧩 **Searching Patterns** (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14194311245358984270 GPPT-3 70 71 assistant\n",
      "14194311245358984270 GPPT-3 84 85 assistant\n",
      "14194311245358984270 GPPT-3 73 74 assistant\n",
      "14194311245358984270 GPPT-3 87 88 assistant\n",
      "14194311245358984270 GPPT-3 8 9 assistant\n",
      "14194311245358984270 GPPT-3 17 18 assistant\n",
      "14194311245358984270 GPPT-3 30 31 assistant\n",
      "14194311245358984270 GPPT-3 113 114 assistant\n",
      "14194311245358984270 GPPT-3 264 265 assistant\n",
      "14194311245358984270 GPPT-3 13 14 assistant\n",
      "14194311245358984270 GPPT-3 25 26 assistant\n",
      "14194311245358984270 GPPT-3 359 360 assistant\n",
      "14194311245358984270 GPPT-3 7 8 assistant\n",
      "14194311245358984270 GPPT-3 27 28 Assistant\n",
      "14194311245358984270 GPPT-3 5 6 assistant\n",
      "14194311245358984270 GPPT-3 7 8 assistant\n",
      "14194311245358984270 GPPT-3 6 7 assistant\n",
      "14194311245358984270 GPPT-3 7 8 assistant\n",
      "14194311245358984270 GPPT-3 7 8 assistant\n",
      "14194311245358984270 GPPT-3 7 8 assistant\n",
      "14194311245358984270 GPPT-3 7 8 assistant\n",
      "14194311245358984270 GPPT-3 7 8 assistant\n",
      "14194311245358984270 GPPT-3 60 61 Assistant\n",
      "14194311245358984270 GPPT-3 74 75 assistant\n",
      "14194311245358984270 GPPT-3 133 134 Assistant\n",
      "14194311245358984270 GPPT-3 59 60 Assistant\n",
      "14194311245358984270 GPPT-3 73 74 assistant\n",
      "14194311245358984270 GPPT-3 132 133 Assistant\n",
      "14194311245358984270 GPPT-3 49 50 Assistant\n",
      "14194311245358984270 GPPT-3 60 61 Assistant\n",
      "14194311245358984270 GPPT-3 74 75 assistant\n",
      "14194311245358984270 GPPT-3 133 134 Assistant\n",
      "14194311245358984270 GPPT-3 59 60 Assistant\n",
      "14194311245358984270 GPPT-3 73 74 assistant\n",
      "14194311245358984270 GPPT-3 132 133 Assistant\n",
      "14194311245358984270 GPPT-3 46 47 Assistant\n",
      "14194311245358984270 GPPT-3 60 61 Assistant\n",
      "14194311245358984270 GPPT-3 74 75 assistant\n",
      "14194311245358984270 GPPT-3 133 134 Assistant\n",
      "14194311245358984270 GPPT-3 12 13 assistant\n",
      "14194311245358984270 GPPT-3 7 8 assistant\n",
      "14194311245358984270 GPPT-3 6 7 assistant\n",
      "14194311245358984270 GPPT-3 7 8 assistant\n",
      "14194311245358984270 GPPT-3 7 8 assistant\n",
      "14194311245358984270 GPPT-3 6 7 assistant\n",
      "14194311245358984270 GPPT-3 23 24 assistant\n",
      "14194311245358984270 GPPT-3 22 23 assistant\n",
      "14194311245358984270 GPPT-3 87 88 assistant\n",
      "14194311245358984270 GPPT-3 7 8 assistant\n",
      "14194311245358984270 GPPT-3 8 9 assistant\n",
      "14194311245358984270 GPPT-3 7 8 assistant\n",
      "14194311245358984270 GPPT-3 6 7 assistant\n",
      "14194311245358984270 GPPT-3 7 8 assistant\n",
      "14194311245358984270 GPPT-3 7 8 assistant\n",
      "14194311245358984270 GPPT-3 7 8 assistant\n",
      "14194311245358984270 GPPT-3 6 7 assistant\n",
      "14194311245358984270 GPPT-3 7 8 assistant\n",
      "14194311245358984270 GPPT-3 7 8 assistant\n",
      "14194311245358984270 GPPT-3 7 8 assistant\n",
      "14194311245358984270 GPPT-3 7 8 assistant\n",
      "14194311245358984270 GPPT-3 7 8 assistant\n",
      "14194311245358984270 GPPT-3 12 13 assistant\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# Add match ID \"HelloWorld\" with no callback and one pattern\n",
    "patterns = [\n",
    "    [{\"LOWER\": \"assistant\"}],\n",
    "]\n",
    "\n",
    "matcher.add(\"GPPT-3\", patterns)\n",
    "\n",
    "def find_pattern(text, patterns):\n",
    "    doc = nlp(text)\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "        span = doc[start:end]  # The matched span\n",
    "        print(match_id, string_id, start, end, span.text)\n",
    "\n",
    "    return matches\n",
    "\n",
    "count = 0\n",
    "for p in high_density_repo_prompts:\n",
    "    if find_pattern(p, patterns):\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
