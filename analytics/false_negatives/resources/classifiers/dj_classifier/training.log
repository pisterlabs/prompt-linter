2023-12-01 23:08:55,593 ----------------------------------------------------------------------------------------------------
2023-12-01 23:08:55,594 Model: "TextClassifier(
  (embeddings): TransformerDocumentEmbeddings(
    (model): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30523, 768)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0-5): 6 x TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
  )
  (decoder): Linear(in_features=768, out_features=2, bias=True)
  (dropout): Dropout(p=0.0, inplace=False)
  (locked_dropout): LockedDropout(p=0.0)
  (word_dropout): WordDropout(p=0.0)
  (loss_function): CrossEntropyLoss()
  (weights): None
  (weight_tensor) None
)"
2023-12-01 23:08:55,595 ----------------------------------------------------------------------------------------------------
2023-12-01 23:08:55,596 Corpus: 6237 train + 2079 dev + 2080 test sentences
2023-12-01 23:08:55,596 ----------------------------------------------------------------------------------------------------
2023-12-01 23:08:55,597 Train:  6237 sentences
2023-12-01 23:08:55,597         (train_with_dev=False, train_with_test=False)
2023-12-01 23:08:55,598 ----------------------------------------------------------------------------------------------------
2023-12-01 23:08:55,598 Training Params:
2023-12-01 23:08:55,598  - learning_rate: "5e-05" 
2023-12-01 23:08:55,599  - mini_batch_size: "4"
2023-12-01 23:08:55,599  - max_epochs: "10"
2023-12-01 23:08:55,600  - shuffle: "True"
2023-12-01 23:08:55,600 ----------------------------------------------------------------------------------------------------
2023-12-01 23:08:55,600 Plugins:
2023-12-01 23:08:55,601  - LinearScheduler | warmup_fraction: '0.1'
2023-12-01 23:08:55,602 ----------------------------------------------------------------------------------------------------
2023-12-01 23:08:55,602 Final evaluation on model after last epoch (final-model.pt)
2023-12-01 23:08:55,602  - metric: "('micro avg', 'f1-score')"
2023-12-01 23:08:55,603 ----------------------------------------------------------------------------------------------------
2023-12-01 23:08:55,603 Computation:
2023-12-01 23:08:55,604  - compute on device: cuda:0
2023-12-01 23:08:55,604  - embedding storage: none
2023-12-01 23:08:55,604 ----------------------------------------------------------------------------------------------------
2023-12-01 23:08:55,605 Model training base path: "resources/classifiers/dj_classifier"
2023-12-01 23:08:55,606 ----------------------------------------------------------------------------------------------------
2023-12-01 23:08:55,606 ----------------------------------------------------------------------------------------------------
2023-12-01 23:09:02,743 epoch 1 - iter 156/1560 - loss 0.59655272 - time (sec): 7.14 - samples/sec: 87.44 - lr: 0.000005 - momentum: 0.000000
2023-12-01 23:09:10,298 epoch 1 - iter 312/1560 - loss 0.47436269 - time (sec): 14.69 - samples/sec: 84.95 - lr: 0.000010 - momentum: 0.000000
2023-12-01 23:09:17,210 epoch 1 - iter 468/1560 - loss 0.41976239 - time (sec): 21.60 - samples/sec: 86.66 - lr: 0.000015 - momentum: 0.000000
2023-12-01 23:09:24,163 epoch 1 - iter 624/1560 - loss 0.37826922 - time (sec): 28.56 - samples/sec: 87.41 - lr: 0.000020 - momentum: 0.000000
2023-12-01 23:09:30,495 epoch 1 - iter 780/1560 - loss 0.35901818 - time (sec): 34.89 - samples/sec: 89.43 - lr: 0.000025 - momentum: 0.000000
2023-12-01 23:09:36,907 epoch 1 - iter 936/1560 - loss 0.35199853 - time (sec): 41.30 - samples/sec: 90.65 - lr: 0.000030 - momentum: 0.000000
2023-12-01 23:09:43,105 epoch 1 - iter 1092/1560 - loss 0.33022105 - time (sec): 47.50 - samples/sec: 91.96 - lr: 0.000035 - momentum: 0.000000
2023-12-01 23:09:48,627 epoch 1 - iter 1248/1560 - loss 0.32008290 - time (sec): 53.02 - samples/sec: 94.15 - lr: 0.000040 - momentum: 0.000000
2023-12-01 23:09:54,439 epoch 1 - iter 1404/1560 - loss 0.30457495 - time (sec): 58.83 - samples/sec: 95.46 - lr: 0.000045 - momentum: 0.000000
2023-12-01 23:10:00,480 epoch 1 - iter 1560/1560 - loss 0.29492066 - time (sec): 64.87 - samples/sec: 96.14 - lr: 0.000050 - momentum: 0.000000
2023-12-01 23:10:00,481 ----------------------------------------------------------------------------------------------------
2023-12-01 23:10:00,482 EPOCH 1 done: loss 0.2949 - lr: 0.000050
2023-12-01 23:10:08,419 DEV : loss 0.32253116369247437 - f1-score (micro avg)  0.9312
2023-12-01 23:10:09,124 ----------------------------------------------------------------------------------------------------
2023-12-01 23:10:14,967 epoch 2 - iter 156/1560 - loss 0.24015913 - time (sec): 5.84 - samples/sec: 106.81 - lr: 0.000049 - momentum: 0.000000
2023-12-01 23:10:21,146 epoch 2 - iter 312/1560 - loss 0.19827982 - time (sec): 12.02 - samples/sec: 103.82 - lr: 0.000049 - momentum: 0.000000
2023-12-01 23:10:27,069 epoch 2 - iter 468/1560 - loss 0.18887304 - time (sec): 17.94 - samples/sec: 104.33 - lr: 0.000048 - momentum: 0.000000
2023-12-01 23:10:33,060 epoch 2 - iter 624/1560 - loss 0.18495171 - time (sec): 23.94 - samples/sec: 104.28 - lr: 0.000048 - momentum: 0.000000
2023-12-01 23:10:39,617 epoch 2 - iter 780/1560 - loss 0.16338223 - time (sec): 30.49 - samples/sec: 102.32 - lr: 0.000047 - momentum: 0.000000
2023-12-01 23:10:46,089 epoch 2 - iter 936/1560 - loss 0.16536068 - time (sec): 36.96 - samples/sec: 101.29 - lr: 0.000047 - momentum: 0.000000
2023-12-01 23:10:52,782 epoch 2 - iter 1092/1560 - loss 0.16635185 - time (sec): 43.66 - samples/sec: 100.05 - lr: 0.000046 - momentum: 0.000000
2023-12-01 23:10:58,801 epoch 2 - iter 1248/1560 - loss 0.16541778 - time (sec): 49.68 - samples/sec: 100.49 - lr: 0.000046 - momentum: 0.000000
2023-12-01 23:11:05,401 epoch 2 - iter 1404/1560 - loss 0.16516729 - time (sec): 56.28 - samples/sec: 99.79 - lr: 0.000045 - momentum: 0.000000
2023-12-01 23:11:11,304 epoch 2 - iter 1560/1560 - loss 0.15929731 - time (sec): 62.18 - samples/sec: 100.31 - lr: 0.000044 - momentum: 0.000000
2023-12-01 23:11:11,305 ----------------------------------------------------------------------------------------------------
2023-12-01 23:11:11,306 EPOCH 2 done: loss 0.1593 - lr: 0.000044
2023-12-01 23:11:19,526 DEV : loss 0.18964089453220367 - f1-score (micro avg)  0.9668
2023-12-01 23:11:20,317 ----------------------------------------------------------------------------------------------------
2023-12-01 23:11:26,522 epoch 3 - iter 156/1560 - loss 0.11978290 - time (sec): 6.20 - samples/sec: 100.60 - lr: 0.000044 - momentum: 0.000000
2023-12-01 23:11:33,073 epoch 3 - iter 312/1560 - loss 0.13653620 - time (sec): 12.75 - samples/sec: 97.85 - lr: 0.000043 - momentum: 0.000000
2023-12-01 23:11:39,601 epoch 3 - iter 468/1560 - loss 0.12463499 - time (sec): 19.28 - samples/sec: 97.09 - lr: 0.000043 - momentum: 0.000000
2023-12-01 23:11:46,170 epoch 3 - iter 624/1560 - loss 0.11369756 - time (sec): 25.85 - samples/sec: 96.55 - lr: 0.000042 - momentum: 0.000000
2023-12-01 23:11:52,755 epoch 3 - iter 780/1560 - loss 0.10932496 - time (sec): 32.44 - samples/sec: 96.19 - lr: 0.000042 - momentum: 0.000000
2023-12-01 23:11:59,265 epoch 3 - iter 936/1560 - loss 0.10408641 - time (sec): 38.95 - samples/sec: 96.13 - lr: 0.000041 - momentum: 0.000000
2023-12-01 23:12:05,305 epoch 3 - iter 1092/1560 - loss 0.10036182 - time (sec): 44.99 - samples/sec: 97.10 - lr: 0.000041 - momentum: 0.000000
2023-12-01 23:12:11,795 epoch 3 - iter 1248/1560 - loss 0.10232572 - time (sec): 51.48 - samples/sec: 96.98 - lr: 0.000040 - momentum: 0.000000
2023-12-01 23:12:18,079 epoch 3 - iter 1404/1560 - loss 0.10366464 - time (sec): 57.76 - samples/sec: 97.23 - lr: 0.000039 - momentum: 0.000000
2023-12-01 23:12:24,144 epoch 3 - iter 1560/1560 - loss 0.10337268 - time (sec): 63.83 - samples/sec: 97.72 - lr: 0.000039 - momentum: 0.000000
2023-12-01 23:12:24,145 ----------------------------------------------------------------------------------------------------
2023-12-01 23:12:24,146 EPOCH 3 done: loss 0.1034 - lr: 0.000039
2023-12-01 23:12:32,375 DEV : loss 0.2323296219110489 - f1-score (micro avg)  0.9514
2023-12-01 23:12:33,216 ----------------------------------------------------------------------------------------------------
2023-12-01 23:12:39,305 epoch 4 - iter 156/1560 - loss 0.07291503 - time (sec): 6.09 - samples/sec: 102.51 - lr: 0.000038 - momentum: 0.000000
2023-12-01 23:12:46,819 epoch 4 - iter 312/1560 - loss 0.07241866 - time (sec): 13.60 - samples/sec: 91.76 - lr: 0.000038 - momentum: 0.000000
2023-12-01 23:12:52,906 epoch 4 - iter 468/1560 - loss 0.07438704 - time (sec): 19.69 - samples/sec: 95.08 - lr: 0.000037 - momentum: 0.000000
2023-12-01 23:12:59,102 epoch 4 - iter 624/1560 - loss 0.07190154 - time (sec): 25.88 - samples/sec: 96.43 - lr: 0.000037 - momentum: 0.000000
2023-12-01 23:13:05,621 epoch 4 - iter 780/1560 - loss 0.07240413 - time (sec): 32.40 - samples/sec: 96.29 - lr: 0.000036 - momentum: 0.000000
2023-12-01 23:13:11,838 epoch 4 - iter 936/1560 - loss 0.06908710 - time (sec): 38.62 - samples/sec: 96.94 - lr: 0.000036 - momentum: 0.000000
2023-12-01 23:13:18,318 epoch 4 - iter 1092/1560 - loss 0.06919046 - time (sec): 45.10 - samples/sec: 96.85 - lr: 0.000035 - momentum: 0.000000
2023-12-01 23:13:24,587 epoch 4 - iter 1248/1560 - loss 0.06906090 - time (sec): 51.37 - samples/sec: 97.18 - lr: 0.000034 - momentum: 0.000000
2023-12-01 23:13:30,790 epoch 4 - iter 1404/1560 - loss 0.07238315 - time (sec): 57.57 - samples/sec: 97.55 - lr: 0.000034 - momentum: 0.000000
2023-12-01 23:13:37,363 epoch 4 - iter 1560/1560 - loss 0.06928827 - time (sec): 64.14 - samples/sec: 97.23 - lr: 0.000033 - momentum: 0.000000
2023-12-01 23:13:37,364 ----------------------------------------------------------------------------------------------------
2023-12-01 23:13:37,365 EPOCH 4 done: loss 0.0693 - lr: 0.000033
2023-12-01 23:13:45,887 DEV : loss 0.2531017065048218 - f1-score (micro avg)  0.9625
2023-12-01 23:13:46,690 ----------------------------------------------------------------------------------------------------
2023-12-01 23:13:53,352 epoch 5 - iter 156/1560 - loss 0.05363817 - time (sec): 6.66 - samples/sec: 93.69 - lr: 0.000033 - momentum: 0.000000
2023-12-01 23:13:59,703 epoch 5 - iter 312/1560 - loss 0.05013372 - time (sec): 13.01 - samples/sec: 95.91 - lr: 0.000032 - momentum: 0.000000
2023-12-01 23:14:06,061 epoch 5 - iter 468/1560 - loss 0.05060938 - time (sec): 19.37 - samples/sec: 96.64 - lr: 0.000032 - momentum: 0.000000
2023-12-01 23:14:12,717 epoch 5 - iter 624/1560 - loss 0.05066536 - time (sec): 26.03 - samples/sec: 95.90 - lr: 0.000031 - momentum: 0.000000
2023-12-01 23:14:19,867 epoch 5 - iter 780/1560 - loss 0.04939224 - time (sec): 33.18 - samples/sec: 94.04 - lr: 0.000031 - momentum: 0.000000
2023-12-01 23:14:26,733 epoch 5 - iter 936/1560 - loss 0.04493995 - time (sec): 40.04 - samples/sec: 93.50 - lr: 0.000030 - momentum: 0.000000
2023-12-01 23:14:33,389 epoch 5 - iter 1092/1560 - loss 0.04887820 - time (sec): 46.70 - samples/sec: 93.54 - lr: 0.000029 - momentum: 0.000000
2023-12-01 23:14:40,016 epoch 5 - iter 1248/1560 - loss 0.04467422 - time (sec): 53.32 - samples/sec: 93.62 - lr: 0.000029 - momentum: 0.000000
2023-12-01 23:14:46,219 epoch 5 - iter 1404/1560 - loss 0.04528822 - time (sec): 59.53 - samples/sec: 94.34 - lr: 0.000028 - momentum: 0.000000
2023-12-01 23:14:53,107 epoch 5 - iter 1560/1560 - loss 0.04500714 - time (sec): 66.42 - samples/sec: 93.91 - lr: 0.000028 - momentum: 0.000000
2023-12-01 23:14:53,108 ----------------------------------------------------------------------------------------------------
2023-12-01 23:14:53,109 EPOCH 5 done: loss 0.0450 - lr: 0.000028
2023-12-01 23:15:01,848 DEV : loss 0.24707025289535522 - f1-score (micro avg)  0.9644
2023-12-01 23:15:02,872 ----------------------------------------------------------------------------------------------------
2023-12-01 23:15:09,169 epoch 6 - iter 156/1560 - loss 0.05932158 - time (sec): 6.29 - samples/sec: 99.13 - lr: 0.000027 - momentum: 0.000000
2023-12-01 23:15:15,105 epoch 6 - iter 312/1560 - loss 0.03567263 - time (sec): 12.23 - samples/sec: 102.04 - lr: 0.000027 - momentum: 0.000000
2023-12-01 23:15:22,071 epoch 6 - iter 468/1560 - loss 0.03747287 - time (sec): 19.20 - samples/sec: 97.51 - lr: 0.000026 - momentum: 0.000000
2023-12-01 23:15:29,027 epoch 6 - iter 624/1560 - loss 0.03806343 - time (sec): 26.15 - samples/sec: 95.44 - lr: 0.000026 - momentum: 0.000000
2023-12-01 23:15:36,102 epoch 6 - iter 780/1560 - loss 0.03333893 - time (sec): 33.23 - samples/sec: 93.90 - lr: 0.000025 - momentum: 0.000000
2023-12-01 23:15:43,618 epoch 6 - iter 936/1560 - loss 0.03425252 - time (sec): 40.74 - samples/sec: 91.89 - lr: 0.000024 - momentum: 0.000000
2023-12-01 23:15:50,987 epoch 6 - iter 1092/1560 - loss 0.03526177 - time (sec): 48.11 - samples/sec: 90.79 - lr: 0.000024 - momentum: 0.000000
2023-12-01 23:15:58,768 epoch 6 - iter 1248/1560 - loss 0.03218914 - time (sec): 55.89 - samples/sec: 89.31 - lr: 0.000023 - momentum: 0.000000
2023-12-01 23:16:05,609 epoch 6 - iter 1404/1560 - loss 0.03541577 - time (sec): 62.74 - samples/sec: 89.52 - lr: 0.000023 - momentum: 0.000000
2023-12-01 23:16:12,289 epoch 6 - iter 1560/1560 - loss 0.04063648 - time (sec): 69.42 - samples/sec: 89.85 - lr: 0.000022 - momentum: 0.000000
2023-12-01 23:16:12,291 ----------------------------------------------------------------------------------------------------
2023-12-01 23:16:12,292 EPOCH 6 done: loss 0.0406 - lr: 0.000022
2023-12-01 23:16:21,639 DEV : loss 0.2291167825460434 - f1-score (micro avg)  0.9673
2023-12-01 23:16:22,664 ----------------------------------------------------------------------------------------------------
2023-12-01 23:16:30,230 epoch 7 - iter 156/1560 - loss 0.03183106 - time (sec): 7.56 - samples/sec: 82.49 - lr: 0.000022 - momentum: 0.000000
2023-12-01 23:16:37,660 epoch 7 - iter 312/1560 - loss 0.01883320 - time (sec): 14.99 - samples/sec: 83.23 - lr: 0.000021 - momentum: 0.000000
2023-12-01 23:16:45,513 epoch 7 - iter 468/1560 - loss 0.03181428 - time (sec): 22.85 - samples/sec: 81.94 - lr: 0.000021 - momentum: 0.000000
2023-12-01 23:16:53,353 epoch 7 - iter 624/1560 - loss 0.02638600 - time (sec): 30.69 - samples/sec: 81.34 - lr: 0.000020 - momentum: 0.000000
2023-12-01 23:17:00,773 epoch 7 - iter 780/1560 - loss 0.02497582 - time (sec): 38.11 - samples/sec: 81.87 - lr: 0.000019 - momentum: 0.000000
2023-12-01 23:17:07,938 epoch 7 - iter 936/1560 - loss 0.02534541 - time (sec): 45.27 - samples/sec: 82.70 - lr: 0.000019 - momentum: 0.000000
2023-12-01 23:17:15,360 epoch 7 - iter 1092/1560 - loss 0.02561861 - time (sec): 52.69 - samples/sec: 82.89 - lr: 0.000018 - momentum: 0.000000
2023-12-01 23:17:22,355 epoch 7 - iter 1248/1560 - loss 0.02589291 - time (sec): 59.69 - samples/sec: 83.63 - lr: 0.000018 - momentum: 0.000000
2023-12-01 23:17:28,718 epoch 7 - iter 1404/1560 - loss 0.02926337 - time (sec): 66.05 - samples/sec: 85.02 - lr: 0.000017 - momentum: 0.000000
2023-12-01 23:17:35,588 epoch 7 - iter 1560/1560 - loss 0.02739436 - time (sec): 72.92 - samples/sec: 85.53 - lr: 0.000017 - momentum: 0.000000
2023-12-01 23:17:35,589 ----------------------------------------------------------------------------------------------------
2023-12-01 23:17:35,590 EPOCH 7 done: loss 0.0274 - lr: 0.000017
2023-12-01 23:17:44,497 DEV : loss 0.26881763339042664 - f1-score (micro avg)  0.9716
2023-12-01 23:17:45,324 ----------------------------------------------------------------------------------------------------
2023-12-01 23:17:52,464 epoch 8 - iter 156/1560 - loss 0.03167180 - time (sec): 7.14 - samples/sec: 87.42 - lr: 0.000016 - momentum: 0.000000
2023-12-01 23:17:58,610 epoch 8 - iter 312/1560 - loss 0.03420513 - time (sec): 13.28 - samples/sec: 93.94 - lr: 0.000016 - momentum: 0.000000
2023-12-01 23:18:05,007 epoch 8 - iter 468/1560 - loss 0.03464628 - time (sec): 19.68 - samples/sec: 95.11 - lr: 0.000015 - momentum: 0.000000
2023-12-01 23:18:11,531 epoch 8 - iter 624/1560 - loss 0.02860863 - time (sec): 26.21 - samples/sec: 95.25 - lr: 0.000014 - momentum: 0.000000
2023-12-01 23:18:18,204 epoch 8 - iter 780/1560 - loss 0.02756507 - time (sec): 32.88 - samples/sec: 94.90 - lr: 0.000014 - momentum: 0.000000
2023-12-01 23:18:25,044 epoch 8 - iter 936/1560 - loss 0.02480234 - time (sec): 39.72 - samples/sec: 94.26 - lr: 0.000013 - momentum: 0.000000
2023-12-01 23:18:31,936 epoch 8 - iter 1092/1560 - loss 0.02444948 - time (sec): 46.61 - samples/sec: 93.71 - lr: 0.000013 - momentum: 0.000000
2023-12-01 23:18:38,544 epoch 8 - iter 1248/1560 - loss 0.02528570 - time (sec): 53.22 - samples/sec: 93.80 - lr: 0.000012 - momentum: 0.000000
2023-12-01 23:18:45,203 epoch 8 - iter 1404/1560 - loss 0.02467085 - time (sec): 59.88 - samples/sec: 93.79 - lr: 0.000012 - momentum: 0.000000
2023-12-01 23:18:52,163 epoch 8 - iter 1560/1560 - loss 0.02324246 - time (sec): 66.84 - samples/sec: 93.32 - lr: 0.000011 - momentum: 0.000000
2023-12-01 23:18:52,164 ----------------------------------------------------------------------------------------------------
2023-12-01 23:18:52,165 EPOCH 8 done: loss 0.0232 - lr: 0.000011
2023-12-01 23:19:01,010 DEV : loss 0.30896320939064026 - f1-score (micro avg)  0.9726
2023-12-01 23:19:01,942 ----------------------------------------------------------------------------------------------------
2023-12-01 23:19:08,423 epoch 9 - iter 156/1560 - loss 0.02712325 - time (sec): 6.48 - samples/sec: 96.30 - lr: 0.000011 - momentum: 0.000000
2023-12-01 23:19:15,434 epoch 9 - iter 312/1560 - loss 0.01380857 - time (sec): 13.49 - samples/sec: 92.51 - lr: 0.000010 - momentum: 0.000000
2023-12-01 23:19:21,842 epoch 9 - iter 468/1560 - loss 0.01935870 - time (sec): 19.90 - samples/sec: 94.08 - lr: 0.000009 - momentum: 0.000000
2023-12-01 23:19:28,334 epoch 9 - iter 624/1560 - loss 0.02006353 - time (sec): 26.39 - samples/sec: 94.58 - lr: 0.000009 - momentum: 0.000000
2023-12-01 23:19:35,202 epoch 9 - iter 780/1560 - loss 0.02184870 - time (sec): 33.26 - samples/sec: 93.81 - lr: 0.000008 - momentum: 0.000000
2023-12-01 23:19:41,983 epoch 9 - iter 936/1560 - loss 0.02004683 - time (sec): 40.04 - samples/sec: 93.51 - lr: 0.000008 - momentum: 0.000000
2023-12-01 23:19:48,684 epoch 9 - iter 1092/1560 - loss 0.02243128 - time (sec): 46.74 - samples/sec: 93.45 - lr: 0.000007 - momentum: 0.000000
2023-12-01 23:19:55,222 epoch 9 - iter 1248/1560 - loss 0.02194020 - time (sec): 53.28 - samples/sec: 93.70 - lr: 0.000007 - momentum: 0.000000
2023-12-01 23:20:02,164 epoch 9 - iter 1404/1560 - loss 0.02257893 - time (sec): 60.22 - samples/sec: 93.26 - lr: 0.000006 - momentum: 0.000000
2023-12-01 23:20:08,520 epoch 9 - iter 1560/1560 - loss 0.02040470 - time (sec): 66.58 - samples/sec: 93.68 - lr: 0.000006 - momentum: 0.000000
2023-12-01 23:20:08,521 ----------------------------------------------------------------------------------------------------
2023-12-01 23:20:08,521 EPOCH 9 done: loss 0.0204 - lr: 0.000006
2023-12-01 23:20:17,172 DEV : loss 0.3203325867652893 - f1-score (micro avg)  0.9745
2023-12-01 23:20:18,004 ----------------------------------------------------------------------------------------------------
2023-12-01 23:20:24,561 epoch 10 - iter 156/1560 - loss 0.01994562 - time (sec): 6.56 - samples/sec: 95.19 - lr: 0.000005 - momentum: 0.000000
2023-12-01 23:20:31,599 epoch 10 - iter 312/1560 - loss 0.01567863 - time (sec): 13.59 - samples/sec: 91.81 - lr: 0.000004 - momentum: 0.000000
2023-12-01 23:20:38,145 epoch 10 - iter 468/1560 - loss 0.01438760 - time (sec): 20.14 - samples/sec: 92.95 - lr: 0.000004 - momentum: 0.000000
2023-12-01 23:20:44,790 epoch 10 - iter 624/1560 - loss 0.01578571 - time (sec): 26.78 - samples/sec: 93.19 - lr: 0.000003 - momentum: 0.000000
2023-12-01 23:20:51,420 epoch 10 - iter 780/1560 - loss 0.01844993 - time (sec): 33.41 - samples/sec: 93.37 - lr: 0.000003 - momentum: 0.000000
2023-12-01 23:20:58,364 epoch 10 - iter 936/1560 - loss 0.01705476 - time (sec): 40.36 - samples/sec: 92.77 - lr: 0.000002 - momentum: 0.000000
2023-12-01 23:21:04,485 epoch 10 - iter 1092/1560 - loss 0.01965948 - time (sec): 46.48 - samples/sec: 93.98 - lr: 0.000002 - momentum: 0.000000
2023-12-01 23:21:10,968 epoch 10 - iter 1248/1560 - loss 0.01842340 - time (sec): 52.96 - samples/sec: 94.26 - lr: 0.000001 - momentum: 0.000000
2023-12-01 23:21:18,077 epoch 10 - iter 1404/1560 - loss 0.02046443 - time (sec): 60.07 - samples/sec: 93.49 - lr: 0.000001 - momentum: 0.000000
2023-12-01 23:21:24,754 epoch 10 - iter 1560/1560 - loss 0.02023694 - time (sec): 66.75 - samples/sec: 93.44 - lr: 0.000000 - momentum: 0.000000
2023-12-01 23:21:24,755 ----------------------------------------------------------------------------------------------------
2023-12-01 23:21:24,756 EPOCH 10 done: loss 0.0202 - lr: 0.000000
2023-12-01 23:21:33,422 DEV : loss 0.3206486105918884 - f1-score (micro avg)  0.9731
2023-12-01 23:21:34,765 ----------------------------------------------------------------------------------------------------
2023-12-01 23:21:34,767 Testing using last state of model ...
2023-12-01 23:21:44,126 
Results:
- F-score (micro) 0.9769
- F-score (macro) 0.9769
- Accuracy 0.9769

By class:
              precision    recall  f1-score   support

           0     0.9781    0.9762    0.9772      1052
           1     0.9757    0.9776    0.9767      1028

    accuracy                         0.9769      2080
   macro avg     0.9769    0.9769    0.9769      2080
weighted avg     0.9769    0.9769    0.9769      2080

2023-12-01 23:21:44,127 ----------------------------------------------------------------------------------------------------
