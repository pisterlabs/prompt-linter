{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Classifier for LLM Prompts\n",
    "# (DON'T LOOK) WORK IN PROGRESS!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: Binary Classification using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def train_llm_prompt_classifier(data, labels):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "    # Convert text to numerical features using TF-IDF\n",
    "    # May not be the best idea for detecting LLM prompts ðŸ˜¬. Let's see how it goes.\n",
    "    tfidf_vectorizer = TfidfVectorizer() \n",
    "\n",
    "    # Use Logistic Regression for classification\n",
    "    classifier = LogisticRegression()\n",
    "\n",
    "    # Create a pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', tfidf_vectorizer),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "\n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"\\n\\nClassifier Performance\\n\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=[\"Non-Prompt\", \"LLM Prompt\"]))\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "classifier = train_llm_prompt_classifier(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_llm_prompt(text, classifier):\n",
    "    prediction = classifier.predict([text])\n",
    "    return prediction[0] == 1\n",
    "\n",
    "example_text = \"Example prompt {question}:\"\n",
    "print(is_llm_prompt(example_text, classifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: Docstrings with certain criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree_sitter import Language, Parser\n",
    "\n",
    "# Load Python grammar\n",
    "TREE_SITTER_PYTHON_PATH = \"tree-sitter-python\"  # Change this according to the cloned path\n",
    "Language.build_library(\n",
    "    \"build/python.so\",\n",
    "    [\n",
    "        TREE_SITTER_PYTHON_PATH,\n",
    "    ],\n",
    ")\n",
    "PYTHON_LANGUAGE = Language(\"build/python.so\", \"python\")\n",
    "\n",
    "# Initialize parser\n",
    "parser = Parser()\n",
    "parser.set_language(PYTHON_LANGUAGE)\n",
    "\n",
    "# Function to check if a node is a docstring\n",
    "def is_docstring_node(node):\n",
    "    return (\n",
    "        node.type == \"string\"\n",
    "        and node.parent\n",
    "        and node.parent.type in [\"module\", \"class_definition\", \"function_definition\"]\n",
    "    )\n",
    "\n",
    "\n",
    "def find_docstrings(tree):\n",
    "    cursor = tree.walk()\n",
    "    docstrings = []\n",
    "\n",
    "    def _traverse(node):\n",
    "        if is_docstring_node(node):\n",
    "            docstrings.append(node)\n",
    "        for child in node.children:\n",
    "            _traverse(child)\n",
    "\n",
    "    _traverse(tree.root_node)\n",
    "\n",
    "    return docstrings\n",
    "\n",
    "\n",
    "# Test the code\n",
    "code = \"\"\"\n",
    "def my_function():\n",
    "    \\\"\\\"\\\"This is a docstring.\\\"\\\"\\\"\n",
    "    pass\n",
    "\n",
    "\\\"\\\"\\\"This is another docstring.\\\"\\\"\\\"\n",
    "\n",
    "class MyClass:\n",
    "    \\\"\\\"\\\"Class docstring.\\\"\\\"\\\"\n",
    "    pass\n",
    "\"\"\"\n",
    "\n",
    "tree = parser.parse(bytes(code, \"utf8\"))\n",
    "\n",
    "docstrings = find_docstrings(tree)\n",
    "\n",
    "for docstring in docstrings:\n",
    "    print(docstring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Test \"\\n\" heuristic against a list of all docstrings assigned to variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 3: Regex to Check for String Interpolation within all strings assigned to variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tree_sitter import Language, Parser\n",
    "\n",
    "# ... (previous code)\n",
    "\n",
    "# Function to check if a docstring uses string interpolation\n",
    "def contains_string_interpolation(docstring_text):\n",
    "    # Check for f-string expressions\n",
    "    f_string_pattern = r'{[^{]*?\\{(.*?)\\}[^}]*?}'\n",
    "    if re.search(f_string_pattern, docstring_text):\n",
    "        return True\n",
    "\n",
    "    # Check for str.format() expressions\n",
    "    str_format_pattern = r'\\{(?:[^{}]+)?\\}'\n",
    "    if re.search(str_format_pattern, docstring_text):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# Test the code\n",
    "code = '''\n",
    "def my_function(arg):\n",
    "    \"\"\"This is a docstring with interpolation: {arg}\"\"\"\n",
    "    pass\n",
    "\n",
    "def another_function(value):\n",
    "    f\"\"\"This is an f-string docstring: {value}\"\"\"\n",
    "    pass\n",
    "'''\n",
    "\n",
    "tree = parser.parse(bytes(code, \"utf8\"))\n",
    "\n",
    "docstrings = find_docstrings(tree)\n",
    "\n",
    "for docstring in docstrings:\n",
    "    docstring_text = code[docstring.start_byte:docstring.end_byte]\n",
    "    print(f\"Docstring: {docstring_text.strip()}\")\n",
    "    print(f\"Contains string interpolation: {contains_string_interpolation(docstring_text)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
